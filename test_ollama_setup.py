#!/usr/bin/env python3
"""
Test script to verify the RunPod Ollama setup is working correctly.
Run this after deploying to RunPod to ensure all components are functional.
"""

import sys
import os
import requests
import json
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

def test_ollama_connection():
    """Test basic Ollama connection"""
    print("ğŸ” Testing Ollama connection...")
    try:
        response = requests.get("http://localhost:11434/api/version", timeout=10)
        if response.status_code == 200:
            version_info = response.json()
            print(f"âœ… Ollama connected successfully - Version: {version_info.get('version', 'unknown')}")
            return True
        else:
            print(f"âŒ Ollama returned status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ollama connection failed: {e}")
        return False

def test_model_availability():
    """Test if the Gemma model is available"""
    print("ğŸ” Testing model availability...")
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json()
            available_models = [model['name'] for model in models.get('models', [])]
            print(f"ğŸ“‹ Available models: {available_models}")
            
            if 'gemma3:27b-instruct' in available_models:
                print("âœ… Gemma 3 27B Instruct model is available")
                return True
            else:
                print("âš ï¸ Gemma 3 27B Instruct model not found. Available models:", available_models)
                return False
        else:
            print(f"âŒ Failed to get model list: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Model check failed: {e}")
        return False

def test_model_inference():
    """Test model inference with a simple prompt"""
    print("ğŸ” Testing model inference...")
    try:
        payload = {
            "model": "gemma3:27b-instruct",
            "prompt": "Hello, please respond with 'AI system ready' if you can understand this message.",
            "stream": False,
            "options": {
                "temperature": 0.1,
                "num_ctx": 4096
            }
        }
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result.get('response', '')
            print(f"âœ… Model inference successful")
            print(f"ğŸ“¤ AI Response: {ai_response.strip()}")
            return True
        else:
            print(f"âŒ Model inference failed: {response.status_code}")
            print(f"ğŸ“„ Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Model inference error: {e}")
        return False

def test_agents():
    """Test both agents"""
    print("ğŸ” Testing agents...")
    try:
        from src.config import Config
        from src.agents.job_matching_agent import JobMatchingAgent
        from src.agents.bias_classification_agent import BiasClassificationAgent
        
        # Test configuration
        config = Config()
        print(f"âœ… Configuration loaded - Model: {config.MODEL_NAME}")
        
        # Test job matching agent
        job_agent = JobMatchingAgent()
        print("âœ… Job Matching Agent initialized")
        
        # Test bias classification agent
        bias_agent = BiasClassificationAgent()
        print("âœ… Bias Classification Agent initialized")
        
        return True
        
    except Exception as e:
        print(f"âŒ Agent test failed: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸš€ RunPod Ollama Setup Test")
    print("=" * 50)
    
    tests = [
        ("Ollama Connection", test_ollama_connection),
        ("Model Availability", test_model_availability),
        ("Model Inference", test_model_inference),
        ("Agent Initialization", test_agents)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nğŸ”„ Running {test_name}...")
        result = test_func()
        results.append((test_name, result))
        print()
    
    # Summary
    print("=" * 50)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nOverall: {passed}/{len(tests)} tests passed")
    
    if passed == len(tests):
        print("ğŸ‰ All tests passed! RunPod setup is ready for production.")
        return 0
    else:
        print("âš ï¸ Some tests failed. Check the output above for details.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
