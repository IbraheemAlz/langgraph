#!/bin/bash
# Complete Fresh Pod Deployment Script
# Combines setup, GPU optimization, and application startup

set -e  # Exit on any error

echo "ğŸ¯ Starting Fresh Pod Deployment for AI Hiring System"
echo "=================================================="

# Step 1: Pull latest changes
echo "ğŸ“¥ Pulling latest changes from repository..."
git pull origin runpod || echo "âš ï¸ Git pull failed or no changes"

# Step 2: Make scripts executable
echo "ğŸ”§ Making scripts executable..."
chmod +x runpod_setup.sh fix_gpu.sh stop_ollama.sh

# Step 3: Run initial setup
echo "âš™ï¸ Running initial setup..."
./runpod_setup.sh

# Step 4: Check if GPU fix is needed
echo "ğŸ” Checking GPU utilization..."
sleep 10

# Test if model is using GPU properly
echo "ğŸ§ª Testing model GPU usage..."
RESPONSE=$(curl -s -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemma3:27b",
    "prompt": "Test",
    "options": {"num_predict": 5},
    "stream": false
  }' || echo "FAILED")

if [[ "$RESPONSE" == *"FAILED"* ]] || [ -z "$RESPONSE" ]; then
    echo "âŒ Model not responding properly - applying GPU fix..."
    ./fix_gpu.sh
else
    echo "âœ… Model responding - checking GPU layer utilization..."
    
    # Check logs for GPU layer usage
    if grep -q "offloaded 1/63 layers to GPU" ollama.log 2>/dev/null; then
        echo "âŒ Only 1/63 layers on GPU - applying GPU fix..."
        ./fix_gpu.sh
    else
        echo "âœ… GPU utilization looks good"
    fi
fi

# Step 5: Final health check
echo "ğŸ¥ Final system health check..."
sleep 5

# Check Ollama
if curl -s http://localhost:11434/api/version > /dev/null; then
    echo "âœ… Ollama service is running"
else
    echo "âŒ Ollama service is not responding"
    exit 1
fi

# Check model availability
if curl -s http://localhost:11434/api/tags | grep -q "gemma3:27b"; then
    echo "âœ… Gemma 3 27B model is available"
else
    echo "âŒ Gemma 3 27B model is not available"
    exit 1
fi

# Step 6: Start the application
echo "ğŸš€ Starting AI Hiring System application..."
python run_on_runpod.py &
APP_PID=$!

# Wait for application to start
echo "â³ Waiting for application startup..."
sleep 15

# Final verification
if curl -s http://localhost:8000/health > /dev/null; then
    echo ""
    echo "ğŸ‰ DEPLOYMENT SUCCESSFUL!"
    echo "================================"
    echo "ğŸ”— Application URL: http://[pod-ip]:8000"
    echo "ğŸ“Š Health Check: http://[pod-ip]:8000/health"
    echo "ğŸ“š API Docs: http://[pod-ip]:8000/docs"
    echo "ğŸ”§ Application PID: $APP_PID"
    echo ""
    echo "ğŸ¯ Ready for batch processing:"
    echo "   python runpod_batch_processor.py --input sample-data.csv"
    echo ""
    echo "ğŸ› ï¸ Management commands:"
    echo "   ./stop_ollama.sh  # Stop Ollama"
    echo "   ./fix_gpu.sh      # Fix GPU utilization"
    echo "   kill $APP_PID     # Stop application"
    echo ""
    echo "ğŸ“ˆ Monitor GPU: watch nvidia-smi"
else
    echo "âŒ Application failed to start properly"
    echo "ğŸ” Check logs: tail -f runpod_deployment.log"
    exit 1
fi
