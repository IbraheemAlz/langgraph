{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e33e25",
   "metadata": {},
   "source": [
    "# Multi-Agent AI Hiring System ğŸ¤–\n",
    "\n",
    "## Professional LangGraph-Based Recruitment Pipeline\n",
    "\n",
    "This comprehensive notebook implements a production-ready Multi-Agent AI Hiring System using **LangGraph**, **Google Gemini**, and **advanced rate limiting**. The system provides both single candidate evaluation and batch CSV processing capabilities.\n",
    "\n",
    "### ğŸš€ Key Features\n",
    "\n",
    "- **ğŸ§  Dual-Agent Architecture**: Job Matching & Bias Classification agents\n",
    "- **ğŸ”„ LangGraph Workflow**: State management with re-evaluation loops\n",
    "- **âš¡ Rate Limiting**: Smart API throttling and retry mechanisms  \n",
    "- **ğŸ“Š Batch Processing**: Efficient CSV processing with progress tracking\n",
    "- **ğŸ›¡ï¸ Error Handling**: Comprehensive exception management and logging\n",
    "- **ğŸ“ˆ Performance Monitoring**: Real-time metrics and resource tracking\n",
    "- **ğŸ’¾ Results Export**: Multiple output formats (JSON, CSV, reports)\n",
    "\n",
    "### ğŸ—ï¸ System Architecture\n",
    "\n",
    "```\n",
    "Input Data â†’ Job Matching Agent â†’ Bias Classification Agent â†’ Decision Logic â†’ Final Output\n",
    "                â†‘                                                    â†“\n",
    "            Re-evaluation â†â†â†â†â†â†â†â†â†â† Bias Detected & < Max Attempts\n",
    "```\n",
    "\n",
    "### ğŸ“‹ Execution Modes\n",
    "\n",
    "1. **Single Candidate Mode**: Interactive evaluation of individual candidates\n",
    "2. **Batch CSV Mode**: High-throughput processing of candidate datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96e41f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies ğŸ“¦\n",
    "\n",
    "Install and configure all required libraries for the multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72e720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported successfully!\n",
      "ğŸ“ Working directory: c:\\Users\\ibrah\\Desktop\\New folder\\langgraph\n",
      "ğŸ Python version: 3.11.4\n",
      "ğŸ”§ Environment loaded: .env file found\n"
     ]
    }
   ],
   "source": [
    "# Core System Dependencies\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Dict, Any, Callable, Optional, Tuple\n",
    "from functools import wraps\n",
    "from collections import deque\n",
    "import warnings\n",
    "\n",
    "# Data Processing & Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Async and Threading\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Environment & Configuration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangGraph & LangChain Dependencies\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Visualization (for later analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure warnings and logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")\n",
    "print(f\"ğŸ“ Working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ Python version: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ”§ Environment loaded: {'.env file found' if os.path.exists('.env') else '.env file not found'}\")\n",
    "\n",
    "# Add current directory to Python path for local imports\n",
    "current_dir = Path.cwd()\n",
    "if str(current_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(current_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b1299",
   "metadata": {},
   "source": [
    "## 2. Configuration Management âš™ï¸\n",
    "\n",
    "Core configuration classes and environment validation for stable system operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b3248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Validating system configuration...\n",
      "âœ… System configuration validated successfully!\n",
      "ğŸ“‹ Model: gemini-1.5-flash-8b\n",
      "ğŸŒ¡ï¸  Temperature: 0.3\n",
      "ğŸ”„ Max re-evaluations: 2\n",
      "âš¡ Rate limit: 5 requests per minute\n",
      "ğŸ“Š Batch size: 10\n",
      "âœ… Config class loaded (exact source code)\n"
     ]
    }
   ],
   "source": [
    "# Configuration Class - Exact from source code\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the Multi-Agent AI Hiring System.\"\"\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    MODEL_NAME = \"gemini-1.5-flash-8b\"\n",
    "    MODEL_TEMPERATURE = 0.3\n",
    "    \n",
    "    # System Configuration\n",
    "    MAX_RE_EVALUATIONS = 2\n",
    "    DEFAULT_BIAS_ON_ERROR = \"unbiased\"\n",
    "    \n",
    "    # Rate Limiting Configuration  \n",
    "    MAX_REQUESTS_PER_MINUTE = 5\n",
    "    BATCH_SIZE = 10\n",
    "    \n",
    "    @classmethod\n",
    "    def validate_environment(cls) -> bool:\n",
    "        \"\"\"Validate that required environment variables are set.\"\"\"\n",
    "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        \n",
    "        if not api_key:\n",
    "            print(\"Missing required API key. Please set GOOGLE_API_KEY in your .env file.\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    @classmethod\n",
    "    def get_model_config(cls) -> dict:\n",
    "        \"\"\"Get configuration for the language model.\"\"\"\n",
    "        return {\n",
    "            \"model\": cls.MODEL_NAME,\n",
    "            \"temperature\": cls.MODEL_TEMPERATURE,\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def get_system_info(cls) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive system configuration info.\"\"\"\n",
    "        return {\n",
    "            \"model_name\": cls.MODEL_NAME,\n",
    "            \"temperature\": cls.MODEL_TEMPERATURE,\n",
    "            \"max_re_evaluations\": cls.MAX_RE_EVALUATIONS,\n",
    "            \"rate_limit\": cls.MAX_REQUESTS_PER_MINUTE,\n",
    "            \"batch_size\": cls.BATCH_SIZE,\n",
    "            \"environment_valid\": cls.validate_environment()\n",
    "        }\n",
    "\n",
    "# Validate environment on load\n",
    "print(\"ğŸ”§ Validating system configuration...\")\n",
    "system_info = Config.get_system_info()\n",
    "\n",
    "if system_info[\"environment_valid\"]:\n",
    "    print(\"âœ… System configuration validated successfully!\")\n",
    "    print(f\"ğŸ“‹ Model: {system_info['model_name']}\")\n",
    "    print(f\"ğŸŒ¡ï¸  Temperature: {system_info['temperature']}\")\n",
    "    print(f\"ğŸ”„ Max re-evaluations: {system_info['max_re_evaluations']}\")\n",
    "    print(f\"âš¡ Rate limit: {system_info['rate_limit']} requests per minute\")\n",
    "    print(f\"ğŸ“Š Batch size: {system_info['batch_size']}\")\n",
    "else:\n",
    "    print(\"âŒ System configuration validation failed!\")\n",
    "    print(\"ğŸ”§ Please check your .env file and API key configuration\")\n",
    "\n",
    "print(\"âœ… Config class loaded (exact source code)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3389f",
   "metadata": {},
   "source": [
    "## 3. Rate Limiting & API Management ğŸš¦\n",
    "\n",
    "This section implements production-ready rate limiting to ensure compliance with Google's API limits and maintain system stability during high-volume operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac2c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rate limiter (exact source code) loaded\n"
     ]
    }
   ],
   "source": [
    "# Rate Limiter Implementation - Exact from source code\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from typing import Callable, Any\n",
    "from functools import wraps\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"Simple thread-safe rate limiter for API calls.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_requests_per_minute: int = 5):\n",
    "        self.max_requests_per_minute = max_requests_per_minute\n",
    "        self.request_times = deque()\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "    def _wait_if_needed(self) -> None:\n",
    "        \"\"\"Wait if we've exceeded the rate limit.\"\"\"\n",
    "        with self.lock:\n",
    "            now = datetime.now()\n",
    "            # Remove requests older than 1 minute\n",
    "            while self.request_times and now - self.request_times[0] > timedelta(minutes=1):\n",
    "                self.request_times.popleft()\n",
    "            \n",
    "            # If we've made too many requests, wait\n",
    "            if len(self.request_times) >= self.max_requests_per_minute:\n",
    "                wait_time = 60.1  # Wait just over a minute\n",
    "                logger.info(f\"â³ Rate limit reached. Waiting {wait_time:.1f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                # Clear old requests after waiting\n",
    "                self.request_times.clear()\n",
    "            \n",
    "            # Add current request\n",
    "            self.request_times.append(now)\n",
    "    \n",
    "    def call_with_rate_limit(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Call a function with rate limiting.\"\"\"\n",
    "        self._wait_if_needed()\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "# Global rate limiter instance (kept for backwards compatibility)\n",
    "_global_rate_limiter = RateLimiter()\n",
    "\n",
    "def rate_limited(func: Callable) -> Callable:\n",
    "    \"\"\"Decorator for rate-limited function calls.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return _global_rate_limiter.call_with_rate_limit(func, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def set_rate_limit(max_requests_per_minute: int) -> None:\n",
    "    \"\"\"Set the global rate limit.\"\"\"\n",
    "    global _global_rate_limiter\n",
    "    _global_rate_limiter = RateLimiter(max_requests_per_minute)\n",
    "    logger.info(f\"âš¡ Rate limiter set to {max_requests_per_minute} requests per minute\")\n",
    "\n",
    "print(\"âœ… Rate limiter (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552651e3",
   "metadata": {},
   "source": [
    "## 4. State Management & Data Structures ğŸ“Š\n",
    "\n",
    "This section defines the state management system using TypedDict for type safety and structured data flow between agents in the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042a20f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Testing state management system...\n",
      "âœ… State management system initialized\n",
      "ğŸ“Š Test candidate: CandidateData(name='Alice Johnson', profile_length=48)\n",
      "ğŸ” State validation: âœ… Valid\n",
      "âœ… No validation errors found\n"
     ]
    }
   ],
   "source": [
    "class HiringState(TypedDict):\n",
    "    \"\"\"State schema for the hiring process.\"\"\"\n",
    "    # Input data\n",
    "    Resume: str\n",
    "    Job_Description: str\n",
    "    Transcript: str\n",
    "    Role: str\n",
    "    \n",
    "    # Process state\n",
    "    decision: str\n",
    "    primary_reason: str\n",
    "    bias_classification: str\n",
    "    re_evaluation_count: int\n",
    "    bias_feedback: str\n",
    "    \n",
    "    # Tracking and insights\n",
    "    evaluation_insights: List[dict]\n",
    "    \n",
    "    # Control\n",
    "    timestamp: str\n",
    "    process_complete: bool\n",
    "\n",
    "class CandidateData:\n",
    "    \"\"\"Enhanced candidate data structure with validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, profile: str, job_requirements: str):\n",
    "        self.name = self._validate_string(name, \"Candidate name\")\n",
    "        self.profile = self._validate_string(profile, \"Candidate profile\")\n",
    "        self.job_requirements = self._validate_string(job_requirements, \"Job requirements\")\n",
    "        self.created_at = datetime.now().isoformat()\n",
    "        \n",
    "    def _validate_string(self, value: str, field_name: str) -> str:\n",
    "        \"\"\"Validate and clean string input.\"\"\"\n",
    "        if not value or not value.strip():\n",
    "            raise ValueError(f\"{field_name} cannot be empty\")\n",
    "        return value.strip()\n",
    "    \n",
    "    def to_state(self, batch_id: Optional[str] = None, \n",
    "                 candidate_index: Optional[int] = None,\n",
    "                 total_candidates: Optional[int] = None) -> HiringState:\n",
    "        \"\"\"Convert to HiringState with default values.\"\"\"\n",
    "        return HiringState(\n",
    "            candidate_name=self.name,\n",
    "            candidate_profile=self.profile,\n",
    "            job_requirements=self.job_requirements,\n",
    "            decision=\"pending\",\n",
    "            decision_reasoning=\"\",\n",
    "            confidence_score=0.0,\n",
    "            bias_detected=\"unknown\",\n",
    "            bias_reasoning=\"\",\n",
    "            bias_confidence=0.0,\n",
    "            re_evaluation_count=0,\n",
    "            re_evaluation_history=[],\n",
    "            processing_timestamp=datetime.now().isoformat(),\n",
    "            processing_duration=0.0,\n",
    "            error_occurred=False,\n",
    "            error_message=\"\",\n",
    "            batch_id=batch_id,\n",
    "            candidate_index=candidate_index,\n",
    "            total_candidates=total_candidates\n",
    "        )\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"CandidateData(name='{self.name}', profile_length={len(self.profile)})\"\n",
    "\n",
    "class StateValidator:\n",
    "    \"\"\"Validates and sanitizes state transitions.\"\"\"\n",
    "    \n",
    "    VALID_DECISIONS = {\"hire\", \"reject\", \"pending\"}\n",
    "    VALID_BIAS_STATES = {\"biased\", \"unbiased\", \"unknown\"}\n",
    "    \n",
    "    @classmethod\n",
    "    def validate_state(cls, state: HiringState) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Comprehensive state validation.\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Validate decisions\n",
    "        if state[\"decision\"] not in cls.VALID_DECISIONS:\n",
    "            errors.append(f\"Invalid decision: {state['decision']}\")\n",
    "        \n",
    "        # Validate bias detection\n",
    "        if state[\"bias_detected\"] not in cls.VALID_BIAS_STATES:\n",
    "            errors.append(f\"Invalid bias state: {state['bias_detected']}\")\n",
    "        \n",
    "        # Validate confidence scores\n",
    "        if not 0.0 <= state[\"confidence_score\"] <= 1.0:\n",
    "            errors.append(f\"Invalid confidence score: {state['confidence_score']}\")\n",
    "        \n",
    "        if not 0.0 <= state[\"bias_confidence\"] <= 1.0:\n",
    "            errors.append(f\"Invalid bias confidence: {state['bias_confidence']}\")\n",
    "        \n",
    "        # Validate re-evaluation count\n",
    "        if state[\"re_evaluation_count\"] < 0:\n",
    "            errors.append(\"Re-evaluation count cannot be negative\")\n",
    "        \n",
    "        if state[\"re_evaluation_count\"] > Config.MAX_RE_EVALUATIONS:\n",
    "            errors.append(f\"Re-evaluation count exceeds maximum: {Config.MAX_RE_EVALUATIONS}\")\n",
    "        \n",
    "        return len(errors) == 0, errors\n",
    "    \n",
    "    @classmethod\n",
    "    def sanitize_state(cls, state: HiringState) -> HiringState:\n",
    "        \"\"\"Sanitize and normalize state values.\"\"\"\n",
    "        # Ensure confidence scores are within bounds\n",
    "        state[\"confidence_score\"] = max(0.0, min(1.0, state[\"confidence_score\"]))\n",
    "        state[\"bias_confidence\"] = max(0.0, min(1.0, state[\"bias_confidence\"]))\n",
    "        \n",
    "        # Ensure valid decisions\n",
    "        if state[\"decision\"] not in cls.VALID_DECISIONS:\n",
    "            state[\"decision\"] = \"pending\"\n",
    "        \n",
    "        # Ensure valid bias states\n",
    "        if state[\"bias_detected\"] not in cls.VALID_BIAS_STATES:\n",
    "            state[\"bias_detected\"] = \"unknown\"\n",
    "        \n",
    "        # Ensure non-negative re-evaluation count\n",
    "        state[\"re_evaluation_count\"] = max(0, state[\"re_evaluation_count\"])\n",
    "        \n",
    "        return state\n",
    "\n",
    "# Test the state management system\n",
    "print(\"ğŸ”§ Testing state management system...\")\n",
    "\n",
    "# Create test candidate\n",
    "test_candidate = CandidateData(\n",
    "    name=\"Alice Johnson\",\n",
    "    profile=\"Software Engineer with 5 years Python experience\",\n",
    "    job_requirements=\"Senior Python Developer position\"\n",
    ")\n",
    "\n",
    "# Convert to state\n",
    "test_state = test_candidate.to_state(batch_id=\"test_batch_1\", candidate_index=1, total_candidates=5)\n",
    "\n",
    "# Validate state\n",
    "is_valid, validation_errors = StateValidator.validate_state(test_state)\n",
    "\n",
    "print(f\"âœ… State management system initialized\")\n",
    "print(f\"ğŸ“Š Test candidate: {test_candidate}\")\n",
    "print(f\"ğŸ” State validation: {'âœ… Valid' if is_valid else 'âŒ Invalid'}\")\n",
    "\n",
    "if validation_errors:\n",
    "    print(f\"âš ï¸  Validation errors: {validation_errors}\")\n",
    "else:\n",
    "    print(\"âœ… No validation errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "772aba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt templates loaded (exact source code)\n",
      "ğŸ“Š Available prompts: ['job_matching_initial', 'job_matching_feedback', 'bias_classification', 'bias_classification_feedback']\n"
     ]
    }
   ],
   "source": [
    "# Prompt Templates - Exact from source code\n",
    "PROMPTS = {\n",
    "    \"job_matching_initial\": \"\"\"\n",
    "**Role:** You are an AI Job Matching Agent, a sophisticated recruitment decision-maker. Your function is to simulate the behavior of a professional and discerning hiring manager, making a hiring decision based on a candidate's qualifications, demonstrated competencies, and alignment with a specific job role.\n",
    "\n",
    "**Objective:** Your sole task is to analyze the provided documents and output a binary classification (\"select\" or \"reject\") along with a brief justification.\n",
    "\n",
    "**Core Instructions:**\n",
    "\n",
    "1. **Analyze the Job Description:** Scrutinize the **Job Description** to identify the key requirements, mandatory skills, experience level, and core responsibilities of the position.\n",
    "2. **Analyze the Resume:** Examine the candidate's **Resume** to evaluate their skills, work history, and qualifications.\n",
    "3. **Analyze the Interview Transcript:** Review the **Transcript** to assess the candidate's communication skills, cultural fit, and ability to articulate their experiences.\n",
    "4. **Make Decision:** Based on your analysis, make a binary decision: \"select\" (if the candidate should be hired) or \"reject\" (if the candidate should not be hired).\n",
    "\n",
    "**Decision Criteria:**\n",
    "- **Technical Competence:** Does the candidate possess the required technical skills and experience?\n",
    "- **Role Alignment:** How well does the candidate's background align with the job requirements?\n",
    "- **Experience Level:** Is the candidate's experience appropriate for the role level?\n",
    "- **Communication & Fit:** Based on the transcript, does the candidate demonstrate good communication and potential cultural fit?\n",
    "\n",
    "**Output Format:**\n",
    "Your response must be in the following format:\n",
    "\n",
    "Decision: [select/reject]\n",
    "Primary Reason: [Brief explanation of the main factor that led to your decision]\n",
    "\n",
    "**Example:**\n",
    "Decision: select\n",
    "Primary Reason: Candidate has 5+ years of relevant Python experience, strong problem-solving skills demonstrated in the interview, and shows excellent technical communication abilities that align well with the senior developer role requirements.\n",
    "\n",
    "Now analyze the following:\n",
    "\n",
    "**Resume:** {Resume}\n",
    "\n",
    "**Job Description:** {Job_Description}\n",
    "\n",
    "**Interview Transcript:** {Transcript}\n",
    "\n",
    "**Role:** {Role}\n",
    "\"\"\",\n",
    "\n",
    "    \"job_matching_feedback\": \"\"\"\n",
    "**Role:** You are an AI Job Matching Agent conducting a RE-EVALUATION of a previous hiring decision due to potential bias concerns.\n",
    "\n",
    "**Context:** Your previous decision has been flagged for potential bias. You must now re-evaluate the candidate with heightened awareness of fairness and objectivity.\n",
    "\n",
    "**Bias Feedback:** {feedback}\n",
    "\n",
    "**Core Instructions:**\n",
    "\n",
    "1. **Review Previous Decision:** Your previous decision was \"{decision}\" with reason: \"{primary_reason}\"\n",
    "2. **Consider Bias Concerns:** The bias feedback indicates potential issues in your evaluation process\n",
    "3. **Re-evaluate Objectively:** Focus strictly on job-relevant qualifications and merit-based factors\n",
    "4. **Avoid Bias Factors:** Do not consider factors like:\n",
    "   - Personal demographics or background\n",
    "   - Subjective cultural preferences\n",
    "   - Assumptions based on name, education prestige, or location\n",
    "   - Communication style preferences that aren't job-critical\n",
    "\n",
    "**Decision Criteria (Re-evaluation):**\n",
    "- **Technical Skills Only:** Focus on demonstrable technical competencies\n",
    "- **Experience Relevance:** Consider only directly relevant work experience\n",
    "- **Job Requirements:** Strict alignment with stated job requirements\n",
    "- **Objective Assessment:** Base decisions on quantifiable qualifications\n",
    "\n",
    "**Output Format:**\n",
    "Decision: [select/reject]\n",
    "Primary Reason: [Merit-based explanation focusing on technical qualifications and job requirements]\n",
    "\n",
    "**Previous Evaluation:**\n",
    "Decision: {decision}\n",
    "Primary Reason: {primary_reason}\n",
    "\n",
    "**Bias Feedback:** {feedback}\n",
    "\n",
    "Now re-evaluate:\n",
    "\n",
    "**Resume:** {Resume}\n",
    "\n",
    "**Job Description:** {Job_Description}\n",
    "\n",
    "**Interview Transcript:** {Transcript}\n",
    "\n",
    "**Role:** {Role}\n",
    "\"\"\",\n",
    "\n",
    "    \"bias_classification\": \"\"\"\n",
    "**Role:** You are an AI Bias Classification Agent, an independent fairness auditor for hiring decisions. Your function is to detect potential bias in hiring decisions and ensure fair, equitable candidate evaluation.\n",
    "\n",
    "**Objective:** Analyze the hiring decision and classify whether it shows evidence of bias or unfair treatment.\n",
    "\n",
    "**Analysis Framework:**\n",
    "\n",
    "1. **Review Decision Context:**\n",
    "   - Candidate background and qualifications\n",
    "   - Job requirements and role expectations\n",
    "   - Hiring decision and stated reasoning\n",
    "\n",
    "2. **Bias Detection Areas:**\n",
    "   - **Demographic Bias:** Unfair treatment based on name, background, or demographic indicators\n",
    "   - **Experience Bias:** Unrealistic experience requirements or prestige preferences\n",
    "   - **Communication Bias:** Penalizing candidates for communication style rather than substance\n",
    "   - **Cultural Bias:** Preferences for specific cultural backgrounds or \"fit\" criteria\n",
    "\n",
    "3. **Fairness Assessment:**\n",
    "   - Are the decision criteria job-relevant?\n",
    "   - Is the reasoning based on merit and qualifications?\n",
    "   - Are there any subjective or prejudicial elements?\n",
    "\n",
    "**Classification Criteria:**\n",
    "- **unbiased:** Decision is fair, merit-based, and free from discriminatory factors\n",
    "- **biased:** Decision shows clear evidence of unfair treatment or discriminatory reasoning\n",
    "\n",
    "**Output Format:**\n",
    "Classification: [unbiased/biased]\n",
    "Reasoning: [Detailed explanation of your bias assessment]\n",
    "\n",
    "**If bias is detected, provide specific feedback for re-evaluation**\n",
    "\n",
    "Now analyze this hiring decision:\n",
    "\n",
    "**Resume:** {Resume}\n",
    "\n",
    "**Job Description:** {Job_Description}\n",
    "\n",
    "**Interview Transcript:** {Transcript}\n",
    "\n",
    "**Role:** {Role}\n",
    "\n",
    "**Decision:** {decision}\n",
    "\n",
    "**Decision Reasoning:** {primary_reason}\n",
    "\"\"\",\n",
    "\n",
    "    \"bias_classification_feedback\": \"\"\"\n",
    "**Role:** You are an AI Bias Classification Agent conducting a FOLLOW-UP bias assessment after a re-evaluation.\n",
    "\n",
    "**Context:** A previous hiring decision was flagged for bias and has been re-evaluated. You must now assess whether the new decision addresses the bias concerns.\n",
    "\n",
    "**Previous Bias Feedback:** {previous_feedback}\n",
    "\n",
    "**Analysis Framework:**\n",
    "\n",
    "1. **Compare Decisions:**\n",
    "   - Original decision: {original_decision}\n",
    "   - Re-evaluated decision: {decision}\n",
    "   - Changes in reasoning approach\n",
    "\n",
    "2. **Bias Remediation Assessment:**\n",
    "   - Has the bias concern been addressed?\n",
    "   - Is the new reasoning more objective and merit-based?\n",
    "   - Are job-relevant criteria now the primary focus?\n",
    "\n",
    "3. **Final Fairness Check:**\n",
    "   - Overall fairness of the final decision\n",
    "   - Adherence to equal opportunity principles\n",
    "   - Merit-based evaluation standards\n",
    "\n",
    "**Classification Criteria:**\n",
    "- **unbiased:** Re-evaluation successfully addressed bias concerns with fair, merit-based reasoning\n",
    "- **biased:** Bias concerns persist despite re-evaluation\n",
    "\n",
    "**Output Format:**\n",
    "Classification: [unbiased/biased]\n",
    "Reasoning: [Assessment of bias remediation and final decision fairness]\n",
    "\n",
    "**Previous Context:**\n",
    "Original Decision: {original_decision}\n",
    "Previous Bias Feedback: {previous_feedback}\n",
    "\n",
    "**Current Evaluation:**\n",
    "**Resume:** {Resume}\n",
    "**Job Description:** {Job_Description}\n",
    "**Interview Transcript:** {Transcript}\n",
    "**Role:** {Role}\n",
    "**Re-evaluated Decision:** {decision}\n",
    "**Re-evaluated Reasoning:** {primary_reason}\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Prompt templates loaded (exact source code)\")\n",
    "print(f\"ğŸ“Š Available prompts: {list(PROMPTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5f305",
   "metadata": {},
   "source": [
    "## 5. AI Agent Implementations ğŸ¤–\n",
    "\n",
    "This section implements the core AI agents: Job Matching Agent for candidate evaluation and Bias Classification Agent for fairness detection. Both agents include retry mechanisms and comprehensive error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6498026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JobMatchingAgent (exact source code) loaded\n"
     ]
    }
   ],
   "source": [
    "class JobMatchingAgent:\n",
    "    \"\"\"\n",
    "    Job Matching Agent for the Multi-Agent AI Hiring System.\n",
    "    \n",
    "    This agent acts as the primary hiring decision-maker, evaluating candidates\n",
    "    based solely on merit-based features like skills, experience, and job alignment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Job Matching Agent with configured model and prompts.\"\"\"\n",
    "        if not Config.validate_environment():\n",
    "            raise ValueError(\"Missing required environment variables\")\n",
    "            \n",
    "        model_config = Config.get_model_config()\n",
    "        self.llm = ChatGoogleGenerativeAI(**model_config)\n",
    "        \n",
    "        self.initial_prompt_template = ChatPromptTemplate.from_template(\n",
    "            PROMPTS[\"job_matching_initial\"]\n",
    "        )\n",
    "        self.feedback_prompt_template = ChatPromptTemplate.from_template(\n",
    "            PROMPTS[\"job_matching_feedback\"]\n",
    "        )\n",
    "\n",
    "    @rate_limited\n",
    "    def _invoke_llm_chain(self, chain, params):\n",
    "        \"\"\"Rate-limited LLM chain invocation.\"\"\"\n",
    "        return chain.invoke(params)\n",
    "\n",
    "    def _extract_retry_delay_from_error(self, error_message: str) -> int:\n",
    "        \"\"\"Extract retry delay from Google API error message.\"\"\"\n",
    "        try:\n",
    "            # Look for retry_delay seconds in the error message\n",
    "            match = re.search(r'retry_delay\\s*{\\s*seconds:\\s*(\\d+)', str(error_message))\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "            \n",
    "            # Fallback: look for other delay patterns\n",
    "            match = re.search(r'wait\\s+(\\d+)\\s+seconds?', str(error_message), re.IGNORECASE)\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract retry delay from error: {e}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _smart_retry_llm_call(self, chain, params):\n",
    "        \"\"\"Smart retry function that respects Google's suggested delays.\"\"\"\n",
    "        max_retries = 3\n",
    "        default_delay = 20\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return self._invoke_llm_chain(chain, params)\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:  # Last attempt\n",
    "                    raise e\n",
    "                \n",
    "                # Extract suggested delay from Google's error message\n",
    "                suggested_delay = self._extract_retry_delay_from_error(str(e))\n",
    "                delay = suggested_delay if suggested_delay is not None else default_delay\n",
    "                \n",
    "                # Add a small buffer to the suggested delay\n",
    "                actual_delay = delay + 5 if suggested_delay else delay\n",
    "                \n",
    "                print(f\"âš ï¸ Job Matching attempt {attempt + 1} failed: {str(e)[:200]}...\")\n",
    "                if suggested_delay:\n",
    "                    print(f\"ğŸ•’ Google suggests waiting {suggested_delay}s, using {actual_delay}s\")\n",
    "                else:\n",
    "                    print(f\"ğŸ•’ Using default delay of {actual_delay}s\")\n",
    "                \n",
    "                print(f\"ğŸ” Retrying in {actual_delay} seconds...\")\n",
    "                time.sleep(actual_delay)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def run(self, Resume: str, Job_Description: str, Transcript: str, Role: str, feedback: str = None) -> dict:\n",
    "        \"\"\"\n",
    "        Make a hiring decision based on candidate information.\n",
    "        \n",
    "        Args:\n",
    "            Resume: Candidate's resume text\n",
    "            Job_Description: Position requirements\n",
    "            Transcript: Interview conversation text\n",
    "            Role: Position title/role\n",
    "            feedback: Optional feedback for re-evaluation\n",
    "            \n",
    "        Returns:\n",
    "            dict: Contains decision and primary_reason\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if feedback:\n",
    "                chain = self.feedback_prompt_template | self.llm\n",
    "                response = self._smart_retry_llm_call(chain, {\n",
    "                    \"Resume\": Resume,\n",
    "                    \"Job_Description\": Job_Description,\n",
    "                    \"Transcript\": Transcript,\n",
    "                    \"Role\": Role,\n",
    "                    \"feedback\": feedback\n",
    "                })\n",
    "            else:\n",
    "                chain = self.initial_prompt_template | self.llm\n",
    "                response = self._smart_retry_llm_call(chain, {\n",
    "                    \"Resume\": Resume,\n",
    "                    \"Job_Description\": Job_Description,\n",
    "                    \"Transcript\": Transcript,\n",
    "                    \"Role\": Role\n",
    "                })\n",
    "            \n",
    "            # Log the response for debugging\n",
    "            print(\"ğŸ” AGENT REASONING:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(response.content)\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            return self._parse_job_matching_response(response.content)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in job matching after all retries: {str(e)}\")\n",
    "            # Return error that will be properly handled by the workflow\n",
    "            raise Exception(f\"Job matching failed after retries: {str(e)}\")\n",
    "    \n",
    "    def _parse_job_matching_response(self, response_text: str) -> dict:\n",
    "        \"\"\"Parse the job matching agent response to extract decision and reasoning from JSON format.\"\"\"\n",
    "        \n",
    "        response_text = response_text.strip()\n",
    "        result = {\n",
    "            \"decision\": \"reject\",\n",
    "            \"primary_reason\": \"Could not determine reason\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # First try to parse as direct JSON\n",
    "            parsed = json.loads(response_text)\n",
    "            \n",
    "            # Extract decision\n",
    "            if \"decision\" in parsed:\n",
    "                decision = parsed[\"decision\"].lower().strip()\n",
    "                if decision in [\"select\", \"reject\"]:\n",
    "                    result[\"decision\"] = decision\n",
    "            \n",
    "            # Extract reasoning - combine array elements or use single string\n",
    "            if \"reasoning\" in parsed:\n",
    "                reasoning = parsed[\"reasoning\"]\n",
    "                if isinstance(reasoning, list):\n",
    "                    result[\"primary_reason\"] = \" | \".join(reasoning)\n",
    "                else:\n",
    "                    result[\"primary_reason\"] = str(reasoning)\n",
    "                    \n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: Extract JSON from text that might contain extra content\n",
    "            json_match = re.search(r'\\{[^{}]*\"decision\"[^{}]*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group())\n",
    "                    \n",
    "                    if \"decision\" in parsed:\n",
    "                        decision = parsed[\"decision\"].lower().strip()\n",
    "                        if decision in [\"select\", \"reject\"]:\n",
    "                            result[\"decision\"] = decision\n",
    "                    \n",
    "                    if \"reasoning\" in parsed:\n",
    "                        reasoning = parsed[\"reasoning\"]\n",
    "                        if isinstance(reasoning, list):\n",
    "                            result[\"primary_reason\"] = \" | \".join(reasoning)\n",
    "                        else:\n",
    "                            result[\"primary_reason\"] = str(reasoning)\n",
    "                            \n",
    "                    return result\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            \n",
    "            # Final fallback: Parse old format if JSON parsing fails\n",
    "            lines = response_text.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Extract decision\n",
    "                if line.lower().startswith('decision:'):\n",
    "                    decision_text = line.split(':', 1)[1].strip().lower()\n",
    "                    if \"select\" in decision_text and \"reject\" not in decision_text:\n",
    "                        result[\"decision\"] = \"select\"\n",
    "                    elif \"reject\" in decision_text:\n",
    "                        result[\"decision\"] = \"reject\"\n",
    "                \n",
    "                # Extract primary reason\n",
    "                elif line.lower().startswith('primary-reason:') or line.lower().startswith('**primary-reason:**'):\n",
    "                    if '**' in line:\n",
    "                        reason_text = line.split('**', 2)[2].strip() if line.count('**') >= 2 else line.split(':', 1)[1].strip()\n",
    "                    else:\n",
    "                        reason_text = line.split(':', 1)[1].strip()\n",
    "                    if reason_text:\n",
    "                        result[\"primary_reason\"] = reason_text\n",
    "            \n",
    "            # Final fallback decision check\n",
    "            if result[\"decision\"] == \"reject\":\n",
    "                decision_lower = response_text.lower()\n",
    "                if \"select\" in decision_lower and \"reject\" not in decision_lower:\n",
    "                    result[\"decision\"] = \"select\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"âœ… JobMatchingAgent (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081d5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BiasClassificationAgent (exact source code) loaded\n"
     ]
    }
   ],
   "source": [
    "class BiasClassificationAgent:\n",
    "    \"\"\"\n",
    "    Bias Classification Agent for the Multi-Agent AI Hiring System.\n",
    "    \n",
    "    This agent acts as an independent fairness auditor, evaluating whether\n",
    "    hiring decisions were influenced by non-merit factors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Bias Classification Agent with configured model and prompts.\"\"\"\n",
    "        if not Config.validate_environment():\n",
    "            raise ValueError(\"Missing required environment variables\")\n",
    "            \n",
    "        model_config = Config.get_model_config()\n",
    "        self.llm = ChatGoogleGenerativeAI(**model_config)\n",
    "        \n",
    "        self.prompt_template = ChatPromptTemplate.from_template(\n",
    "            PROMPTS[\"bias_classification\"]\n",
    "        )\n",
    "        \n",
    "        self.feedback_prompt_template = ChatPromptTemplate.from_template(\n",
    "            PROMPTS[\"bias_classification_feedback\"]\n",
    "        )\n",
    "\n",
    "    @rate_limited\n",
    "    def _invoke_llm_chain(self, chain, params):\n",
    "        \"\"\"Rate-limited LLM chain invocation.\"\"\"\n",
    "        return chain.invoke(params)\n",
    "\n",
    "    def _extract_retry_delay_from_error(self, error_message: str) -> int:\n",
    "        \"\"\"Extract retry delay from Google API error message.\"\"\"\n",
    "        try:\n",
    "            # Look for retry_delay seconds in the error message\n",
    "            match = re.search(r'retry_delay\\s*{\\s*seconds:\\s*(\\d+)', str(error_message))\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "            \n",
    "            # Fallback: look for other delay patterns\n",
    "            match = re.search(r'wait\\s+(\\d+)\\s+seconds?', str(error_message), re.IGNORECASE)\n",
    "            if match:\n",
    "                return int(match.group(1))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Could not extract retry delay from error: {e}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _smart_retry_llm_call(self, chain, params):\n",
    "        \"\"\"Smart retry function that respects Google's suggested delays.\"\"\"\n",
    "        max_retries = 3\n",
    "        default_delay = 20\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return self._invoke_llm_chain(chain, params)\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:  # Last attempt\n",
    "                    raise e\n",
    "                \n",
    "                # Extract suggested delay from Google's error message\n",
    "                suggested_delay = self._extract_retry_delay_from_error(str(e))\n",
    "                delay = suggested_delay if suggested_delay is not None else default_delay\n",
    "                \n",
    "                # Add a small buffer to the suggested delay\n",
    "                actual_delay = delay + 5 if suggested_delay else delay\n",
    "                \n",
    "                print(f\"âš ï¸ Bias Classification attempt {attempt + 1} failed: {str(e)[:200]}...\")\n",
    "                if suggested_delay:\n",
    "                    print(f\"ğŸ•’ Google suggests waiting {suggested_delay}s, using {actual_delay}s\")\n",
    "                else:\n",
    "                    print(f\"ğŸ•’ Using default delay of {actual_delay}s\")\n",
    "                \n",
    "                print(f\"ğŸ” Retrying in {actual_delay} seconds...\")\n",
    "                time.sleep(actual_delay)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def run(self, Resume: str, Job_Description: str, Transcript: str, decision: str, Role: str = \"\", \n",
    "            primary_reason: str = \"\", original_decision: str = \"\", previous_feedback: str = \"\") -> dict:\n",
    "        \"\"\"\n",
    "        Classify whether a hiring decision was biased or unbiased.\n",
    "        \n",
    "        Args:\n",
    "            Resume: Candidate's resume text\n",
    "            Job_Description: Position requirements\n",
    "            Transcript: Interview conversation text\n",
    "            decision: Decision made by job matching agent (\"select\" or \"reject\")\n",
    "            Role: Optional role information\n",
    "            primary_reason: The main reason provided by job matching agent\n",
    "            original_decision: For re-evaluations, the original decision\n",
    "            previous_feedback: For re-evaluations, the previous feedback given\n",
    "            \n",
    "        Returns:\n",
    "            dict: Contains classification and optionally specific_feedback\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Determine if this is initial classification or re-evaluation\n",
    "            is_re_evaluation = bool(original_decision and previous_feedback)\n",
    "            \n",
    "            if is_re_evaluation:\n",
    "                chain = self.feedback_prompt_template | self.llm\n",
    "                params = {\n",
    "                    \"Resume\": Resume,\n",
    "                    \"Job_Description\": Job_Description,\n",
    "                    \"Transcript\": Transcript,\n",
    "                    \"Role\": Role or \"Not specified\",\n",
    "                    \"decision\": decision,\n",
    "                    \"primary_reason\": primary_reason,\n",
    "                    \"original_decision\": original_decision,\n",
    "                    \"previous_feedback\": previous_feedback\n",
    "                }\n",
    "            else:\n",
    "                chain = self.prompt_template | self.llm\n",
    "                params = {\n",
    "                    \"Resume\": Resume,\n",
    "                    \"Job_Description\": Job_Description,\n",
    "                    \"Transcript\": Transcript,\n",
    "                    \"Role\": Role or \"Not specified\",\n",
    "                    \"decision\": decision,\n",
    "                    \"primary_reason\": primary_reason\n",
    "                }\n",
    "            \n",
    "            response = self._smart_retry_llm_call(chain, params)\n",
    "            \n",
    "            # Log the response for debugging (only if bias is detected)\n",
    "            result_preview = self._parse_bias_response(response.content)\n",
    "            if result_preview.get(\"classification\") == \"biased\":\n",
    "                evaluation_type = \"RE-EVALUATION\" if is_re_evaluation else \"INITIAL\"\n",
    "                print(f\"ğŸ” BIAS AGENT {evaluation_type} REASONING:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(response.content)\n",
    "                print(\"-\" * 50)\n",
    "            \n",
    "            return result_preview\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in bias classification after all retries: {str(e)}\")\n",
    "            # Default to unbiased in case of error to avoid false positives\n",
    "            return {\n",
    "                \"classification\": Config.DEFAULT_BIAS_ON_ERROR,\n",
    "                \"specific_feedback\": None\n",
    "            }\n",
    "    \n",
    "    def _parse_bias_response(self, response_text: str) -> dict:\n",
    "        \"\"\"Parse the bias agent response to extract classification and justification from JSON format.\"\"\"\n",
    "        \n",
    "        response_text = response_text.strip()\n",
    "        result = {\n",
    "            \"classification\": \"unbiased\",\n",
    "            \"specific_feedback\": None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # First try to parse as direct JSON\n",
    "            parsed = json.loads(response_text)\n",
    "            \n",
    "            # Extract classification\n",
    "            if \"classification\" in parsed:\n",
    "                classification = parsed[\"classification\"].lower().strip()\n",
    "                if classification in [\"biased\", \"unbiased\"]:\n",
    "                    result[\"classification\"] = classification\n",
    "            \n",
    "            # Extract justification as feedback\n",
    "            if \"justification\" in parsed:\n",
    "                justification = parsed[\"justification\"]\n",
    "                if isinstance(justification, str) and justification.strip():\n",
    "                    result[\"specific_feedback\"] = justification.strip()\n",
    "                    \n",
    "            return result\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: Extract JSON from text that might contain extra content\n",
    "            json_match = re.search(r'\\{[^{}]*\"classification\"[^{}]*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed = json.loads(json_match.group())\n",
    "                    \n",
    "                    if \"classification\" in parsed:\n",
    "                        classification = parsed[\"classification\"].lower().strip()\n",
    "                        if classification in [\"biased\", \"unbiased\"]:\n",
    "                            result[\"classification\"] = classification\n",
    "                    \n",
    "                    if \"justification\" in parsed:\n",
    "                        justification = parsed[\"justification\"]\n",
    "                        if isinstance(justification, str) and justification.strip():\n",
    "                            result[\"specific_feedback\"] = justification.strip()\n",
    "                            \n",
    "                    return result\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            \n",
    "            # Final fallback: Parse old format if JSON parsing fails\n",
    "            lines = response_text.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Extract classification - handle various formats\n",
    "                if (line.lower().startswith('classification:') or \n",
    "                    line.lower().startswith('re-classification:') or\n",
    "                    line.lower().startswith('**classification:**')):\n",
    "                    classification_text = line.split(':', 1)[1].strip().lower()\n",
    "                    # Remove asterisks if present\n",
    "                    classification_text = classification_text.replace('*', '').strip()\n",
    "                    if \"biased\" in classification_text and \"unbiased\" not in classification_text:\n",
    "                        result[\"classification\"] = \"biased\"\n",
    "                    elif \"unbiased\" in classification_text:\n",
    "                        result[\"classification\"] = \"unbiased\"\n",
    "                \n",
    "                # Extract specific feedback - handle various formats\n",
    "                elif (line.lower().startswith('specific-feedback:') or \n",
    "                      line.lower().startswith('additional-feedback:') or\n",
    "                      line.lower().startswith('**specific-feedback:**') or\n",
    "                      line.lower().startswith('**additional-feedback:**')):\n",
    "                    feedback_text = line.split(':', 1)[1].strip()\n",
    "                    # Remove asterisks if present\n",
    "                    feedback_text = feedback_text.replace('*', '').strip()\n",
    "                    if feedback_text and feedback_text.lower() not in ['none', 'n/a', '-']:\n",
    "                        result[\"specific_feedback\"] = feedback_text\n",
    "            \n",
    "            # Final fallback classification check\n",
    "            if result[\"classification\"] == \"unbiased\":\n",
    "                classification_lower = response_text.lower()\n",
    "                if \"biased\" in classification_lower and \"unbiased\" not in classification_lower:\n",
    "                    result[\"classification\"] = \"biased\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"âœ… BiasClassificationAgent (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9fe9b",
   "metadata": {},
   "source": [
    "## 6. LangGraph Workflow Implementation ğŸ”„\n",
    "\n",
    "This section implements the core LangGraph workflow that orchestrates the multi-agent system with automatic re-evaluation loops, state management, and decision routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b254445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph workflow implementation (exact source code) loaded\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Workflow Implementation - Exact from source code\n",
    "\n",
    "def job_matching_node(state: HiringState) -> dict:\n",
    "    \"\"\"Node for job matching with re-evaluation capability.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        agent = JobMatchingAgent()\n",
    "        re_evaluation_count = state.get(\"re_evaluation_count\", 0)\n",
    "        evaluation_number = re_evaluation_count + 1\n",
    "        \n",
    "        # Get bias feedback for re-evaluations\n",
    "        bias_feedback = state.get(\"bias_feedback\", \"\") if re_evaluation_count > 0 else None\n",
    "        \n",
    "        print(f\"---Job Matching Agent (Evaluation #{evaluation_number})---\")\n",
    "        if bias_feedback:\n",
    "            print(f\"ğŸ“ Re-evaluating with bias feedback: {bias_feedback[:100]}...\")\n",
    "        \n",
    "        result = agent.run(\n",
    "            Resume=state.get('Resume', ''),\n",
    "            Job_Description=state.get('Job_Description', ''),\n",
    "            Transcript=state.get('Transcript', ''),\n",
    "            Role=state.get('Role', ''),\n",
    "            feedback=bias_feedback\n",
    "        )\n",
    "        \n",
    "        final_decision = result.get(\"decision\", \"reject\")\n",
    "        primary_reason = result.get(\"primary_reason\", \"No reason provided\")\n",
    "        \n",
    "        print(f\"Decision: {final_decision}\")\n",
    "        print(f\"Primary Reason: {primary_reason}\")\n",
    "        \n",
    "        # Create evaluation insight for this evaluation\n",
    "        evaluation_insight = {\n",
    "            \"evaluation_number\": evaluation_number,\n",
    "            \"decision\": final_decision,\n",
    "            \"primary_reason\": primary_reason,\n",
    "            \"agent\": \"job_matching\",\n",
    "            \"is_re_evaluation\": re_evaluation_count > 0\n",
    "        }\n",
    "        \n",
    "        # Initialize or update evaluation insights list\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        evaluation_insights.append(evaluation_insight)\n",
    "        \n",
    "        return {\n",
    "            \"decision\": final_decision,\n",
    "            \"primary_reason\": primary_reason,\n",
    "            \"evaluation_insights\": evaluation_insights\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in job matching: {str(e)}\")\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        evaluation_insights.append({\n",
    "            \"evaluation_number\": state.get(\"re_evaluation_count\", 0) + 1,\n",
    "            \"decision\": \"reject\",\n",
    "            \"primary_reason\": \"Error in evaluation process\",\n",
    "            \"agent\": \"job_matching\",\n",
    "            \"is_re_evaluation\": state.get(\"re_evaluation_count\", 0) > 0,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        return {\n",
    "            \"decision\": \"reject\",\n",
    "            \"primary_reason\": \"Error in evaluation process\",\n",
    "            \"evaluation_insights\": evaluation_insights\n",
    "        }\n",
    "\n",
    "def bias_classification_node(state: HiringState) -> dict:\n",
    "    \"\"\"Node for bias classification.\"\"\"\n",
    "    print(\"---Bias Classification Agent---\")\n",
    "    \n",
    "    try:\n",
    "        agent = BiasClassificationAgent()\n",
    "        \n",
    "        # Get re-evaluation context\n",
    "        re_evaluation_count = state.get(\"re_evaluation_count\", 0)\n",
    "        original_decision = None\n",
    "        previous_feedback = None\n",
    "        \n",
    "        # For re-evaluations, get original decision and previous feedback\n",
    "        if re_evaluation_count > 0:\n",
    "            evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "            if len(evaluation_insights) >= 2:  # Should have original and current\n",
    "                original_decision = evaluation_insights[0].get(\"decision\", \"\")\n",
    "                # Get previous bias feedback if available\n",
    "                for insight in evaluation_insights:\n",
    "                    if insight.get(\"classification\") == \"biased\" and insight.get(\"specific_feedback\"):\n",
    "                        previous_feedback = insight.get(\"specific_feedback\")\n",
    "                        break\n",
    "        \n",
    "        result = agent.run(\n",
    "            Resume=state.get('Resume', ''),\n",
    "            Job_Description=state.get('Job_Description', ''),\n",
    "            Transcript=state.get('Transcript', ''),\n",
    "            decision=state.get('decision', ''),\n",
    "            Role=state.get('Role', ''),\n",
    "            primary_reason=state.get('primary_reason', ''),\n",
    "            original_decision=original_decision or \"\",\n",
    "            previous_feedback=previous_feedback or \"\"\n",
    "        )\n",
    "        \n",
    "        # Extract classification and feedback\n",
    "        bias_classification = result.get(\"classification\", \"unbiased\")\n",
    "        specific_feedback = result.get(\"specific_feedback\", None)\n",
    "        \n",
    "        # Only log when bias is detected\n",
    "        if bias_classification == \"biased\":\n",
    "            print(f\"Bias Classification: {bias_classification}\")\n",
    "            if specific_feedback:\n",
    "                print(f\"Bias Feedback: {specific_feedback}\")\n",
    "        \n",
    "        # Update the most recent evaluation insight with bias classification\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        if evaluation_insights:\n",
    "            evaluation_insights[-1][\"classification\"] = bias_classification\n",
    "            if specific_feedback:\n",
    "                evaluation_insights[-1][\"specific_feedback\"] = specific_feedback\n",
    "        \n",
    "        result_dict = {\n",
    "            \"bias_classification\": bias_classification,\n",
    "            \"evaluation_insights\": evaluation_insights\n",
    "        }\n",
    "        \n",
    "        # Add bias feedback to state if bias is detected\n",
    "        if bias_classification == \"biased\" and specific_feedback:\n",
    "            result_dict[\"bias_feedback\"] = specific_feedback\n",
    "        \n",
    "        return result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in bias classification: {str(e)}\")\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        if evaluation_insights:\n",
    "            evaluation_insights[-1][\"classification\"] = \"unbiased\"\n",
    "            evaluation_insights[-1][\"error\"] = str(e)\n",
    "        \n",
    "        return {\n",
    "            \"bias_classification\": \"unbiased\",\n",
    "            \"evaluation_insights\": evaluation_insights\n",
    "        }\n",
    "\n",
    "def should_continue(state: HiringState) -> str:\n",
    "    \"\"\"Determine if we should continue or end after bias classification.\"\"\"\n",
    "    bias_classification = state.get(\"bias_classification\", \"unbiased\")\n",
    "    re_evaluation_count = state.get(\"re_evaluation_count\", 0)\n",
    "    max_re_evaluations = Config.MAX_RE_EVALUATIONS\n",
    "    \n",
    "    if bias_classification == \"biased\" and re_evaluation_count < max_re_evaluations:\n",
    "        print(f\"---Bias detected, re-evaluating (attempt {re_evaluation_count + 1})---\")\n",
    "        return \"re_evaluate\"\n",
    "    \n",
    "    print(\"---Decision finalized---\")\n",
    "    return \"finalize\"\n",
    "\n",
    "def re_evaluate_node(state: HiringState) -> dict:\n",
    "    \"\"\"Increment re-evaluation counter for bias-driven re-evaluation.\"\"\"\n",
    "    count = state.get(\"re_evaluation_count\", 0) + 1\n",
    "    bias_feedback = state.get(\"bias_feedback\", \"\")\n",
    "    print(f\"Re-evaluation #{count} triggered by bias detection\")\n",
    "    \n",
    "    # The bias_feedback is already in state from bias classification node\n",
    "    # We need to ensure it persists through the re-evaluation\n",
    "    result = {\n",
    "        \"re_evaluation_count\": count\n",
    "    }\n",
    "    \n",
    "    # Explicitly preserve bias_feedback if it exists\n",
    "    if bias_feedback:\n",
    "        result[\"bias_feedback\"] = bias_feedback\n",
    "    \n",
    "    return result\n",
    "\n",
    "def finalize_node(state: HiringState) -> dict:\n",
    "    \"\"\"Finalize the hiring decision.\"\"\"\n",
    "    print(\"---Finalizing Decision---\")\n",
    "    \n",
    "    decision = state.get(\"decision\", \"reject\")\n",
    "    bias_classification = state.get(\"bias_classification\", \"unbiased\")\n",
    "    re_evaluations = state.get(\"re_evaluation_count\", 0)\n",
    "    evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "    \n",
    "    print(f\"Final Decision: {decision}\")\n",
    "    print(f\"Bias Classification: {bias_classification}\")\n",
    "    print(f\"Re-evaluations: {re_evaluations}\")\n",
    "    \n",
    "    # Log evaluation insights summary\n",
    "    if evaluation_insights:\n",
    "        print(\"ğŸ“Š Evaluation Insights:\")\n",
    "        for insight in evaluation_insights:\n",
    "            eval_type = \"re-evaluation\" if insight.get(\"is_re_evaluation\") else \"initial\"\n",
    "            print(f\"  {eval_type} #{insight['evaluation_number']}: {insight['decision']} â†’ {insight.get('classification', 'pending')}\")\n",
    "    \n",
    "    return {\n",
    "        \"process_complete\": True,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"evaluation_insights\": evaluation_insights\n",
    "    }\n",
    "\n",
    "# 3. Build the Graph - Simplified\n",
    "def create_hiring_workflow():\n",
    "    \"\"\"Create and return the hiring workflow graph.\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(HiringState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"job_matcher\", job_matching_node)\n",
    "    workflow.add_node(\"bias_classifier\", bias_classification_node)\n",
    "    workflow.add_node(\"re_evaluate\", re_evaluate_node)\n",
    "    workflow.add_node(\"finalize\", finalize_node)\n",
    "    \n",
    "    # Add edges - cleaner flow\n",
    "    workflow.add_edge(START, \"job_matcher\")\n",
    "    workflow.add_edge(\"job_matcher\", \"bias_classifier\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"bias_classifier\", \n",
    "        should_continue,\n",
    "        {\n",
    "            \"re_evaluate\": \"re_evaluate\",\n",
    "            \"finalize\": \"finalize\"\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"re_evaluate\", \"job_matcher\")\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Add memory\n",
    "    memory = InMemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "print(\"âœ… LangGraph workflow implementation (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84b426",
   "metadata": {},
   "source": [
    "## 7. Batch Processing & CSV Integration ğŸ“Š\n",
    "\n",
    "This section implements comprehensive batch processing capabilities for handling multiple candidates from CSV files with progress tracking, error handling, and results export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Processing Functions - From source code\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_dataset(csv_path: str, max_rows: int = None) -> pd.DataFrame:\n",
    "    \"\"\"Load and validate dataset from CSV.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"ğŸ“Š Loaded dataset: {len(df)} candidates from {csv_path}\")\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = ['ID', 'Role', 'Job_Description', 'Transcript', 'Resume']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Limit rows if specified\n",
    "        if max_rows and max_rows < len(df):\n",
    "            df = df.head(max_rows)\n",
    "            print(f\"ğŸ”¢ Processing first {max_rows} candidates\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "def process_candidate(workflow, candidate_data: dict, candidate_num: int, total: int, dataset_index: int = 0) -> dict:\n",
    "    \"\"\"Process a single candidate and return results.\"\"\"\n",
    "    candidate_id = candidate_data['ID']\n",
    "    role = candidate_data['Role']\n",
    "    \n",
    "    print(f\"\\n\udccb Processing Candidate {candidate_num}/{total}\")\n",
    "    print(f\"ğŸ†” ID: {candidate_id}\")\n",
    "    print(f\"ğŸ¯ Role: {role}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Configure workflow for this candidate\n",
    "        config = {\"configurable\": {\"thread_id\": f\"candidate_{candidate_id}_{candidate_num}\"}}\n",
    "        \n",
    "        # Run the workflow - retry logic is now handled within the agents\n",
    "        result = workflow.invoke(candidate_data, config)\n",
    "        \n",
    "        # Extract core results from workflow response\n",
    "        final_decision = result.get('decision', 'unknown')\n",
    "        bias_classification = result.get('bias_classification', 'unknown') \n",
    "        re_evaluation_count = result.get('re_evaluation_count', 0)\n",
    "        evaluation_insights = result.get('evaluation_insights', [])\n",
    "        \n",
    "        print(f\"  âœ… Result: {final_decision}\")\n",
    "        if re_evaluation_count > 0:\n",
    "            print(f\"  âš ï¸  Bias detected - {re_evaluation_count} re-evaluation(s)\")\n",
    "        \n",
    "        # Display evaluation insights\n",
    "        if evaluation_insights:\n",
    "            print(f\"  ğŸ“Š Evaluation History:\")\n",
    "            for insight in evaluation_insights:\n",
    "                eval_type = \"re-eval\" if insight.get(\"is_re_evaluation\") else \"initial\"\n",
    "                classification = insight.get(\"classification\", \"pending\")\n",
    "                print(f\"    â€¢ {eval_type} #{insight['evaluation_number']}: {insight['decision']} â†’ {classification}\")\n",
    "        \n",
    "        # Create clean result record\n",
    "        result_record = {\n",
    "            \"candidate_id\": candidate_id,\n",
    "            \"dataset_index\": dataset_index,\n",
    "            \"role\": role,\n",
    "            \"final_decision\": final_decision,\n",
    "            \"bias_classification\": bias_classification,\n",
    "            \"re_evaluation_count\": re_evaluation_count,\n",
    "            \"evaluation_insights\": evaluation_insights,\n",
    "            \"processing_time\": datetime.now().isoformat(),\n",
    "            \"workflow_completed\": True,\n",
    "            \"job_feedback_count\": 1,\n",
    "            \"bias_feedback_count\": 1 + re_evaluation_count\n",
    "        }\n",
    "        \n",
    "        # Include ground truth if available\n",
    "        if 'decision' in candidate_data:\n",
    "            result_record['ground_truth_decision'] = candidate_data['decision']\n",
    "        if 'classification' in candidate_data:\n",
    "            result_record['ground_truth_bias'] = candidate_data['classification']\n",
    "            \n",
    "        return result_record\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {e}\")\n",
    "        \n",
    "        # Return error record\n",
    "        error_record = {\n",
    "            \"candidate_id\": candidate_id,\n",
    "            \"dataset_index\": dataset_index,\n",
    "            \"role\": role,\n",
    "            \"final_decision\": \"error\",\n",
    "            \"bias_classification\": \"error\",\n",
    "            \"re_evaluation_count\": 0,\n",
    "            \"evaluation_insights\": [],\n",
    "            \"processing_time\": datetime.now().isoformat(),\n",
    "            \"workflow_completed\": False,\n",
    "            \"job_feedback_count\": 0,\n",
    "            \"bias_feedback_count\": 0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        \n",
    "        # Include ground truth if available\n",
    "        if 'decision' in candidate_data:\n",
    "            error_record['ground_truth_decision'] = candidate_data['decision']\n",
    "        if 'classification' in candidate_data:\n",
    "            error_record['ground_truth_bias'] = candidate_data['classification']\n",
    "        \n",
    "        return error_record\n",
    "\n",
    "def save_results(results: list, output_path: str = \"results/json/batch_results.json\"):\n",
    "    \"\"\"Save results to JSON file with metadata.\"\"\"\n",
    "    \n",
    "    # Ensure results directory exists\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    total_candidates = len(results)\n",
    "    successful = len([r for r in results if r['workflow_completed'] == True])\n",
    "    errors = total_candidates - successful\n",
    "    \n",
    "    # Create output data\n",
    "    output_data = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_candidates\": total_candidates,\n",
    "            \"successful_evaluations\": successful,\n",
    "            \"errors\": errors,\n",
    "            \"success_rate\": (successful / total_candidates * 100) if total_candidates > 0 else 0,\n",
    "            \"version\": \"batch_processor_v1.0\"\n",
    "        },\n",
    "        \"results\": results\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\udcbe Results saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def print_batch_summary(results: list):\n",
    "    \"\"\"Print processing summary.\"\"\"\n",
    "    total = len(results)\n",
    "    successful = len([r for r in results if r['workflow_completed'] == True])\n",
    "    errors = total - successful\n",
    "    \n",
    "    # Decision statistics (successful only)\n",
    "    success_results = [r for r in results if r['workflow_completed'] == True]\n",
    "    selected = len([r for r in success_results if r['final_decision'] == 'select'])\n",
    "    rejected = len([r for r in success_results if r['final_decision'] == 'reject'])\n",
    "    \n",
    "    # Bias statistics\n",
    "    biased = len([r for r in success_results if r['bias_classification'] == 'biased'])\n",
    "    total_reevals = sum([r['re_evaluation_count'] for r in success_results])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\udcc8 PROCESSING STATISTICS:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"ğŸ“Š Total Candidates: {total}\")\n",
    "    print(f\"âœ… Successful Evaluations: {successful}\")\n",
    "    print(f\"âŒ Errors: {errors}\")\n",
    "    print(f\"ğŸ“Š Success Rate: {(successful/total*100):.1f}%\")\n",
    "    \n",
    "    if success_results:\n",
    "        print(\"\\nğŸ“‹ DECISION STATISTICS:\")\n",
    "        print(\"-\"*30)\n",
    "        print(f\"ğŸ‘ Selected: {selected} ({selected/successful*100:.1f}%)\")\n",
    "        print(f\"ğŸ‘ Rejected: {rejected} ({rejected/successful*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\n\udd0d BIAS ANALYSIS:\")\n",
    "        print(\"-\"*20)\n",
    "        print(f\"âš ï¸  Bias Detected: {biased} ({biased/successful*100:.1f}%)\")\n",
    "        print(f\"ğŸ”„ Total Re-evaluations: {total_reevals}\")\n",
    "        print(f\"\udcca Avg Re-evaluations: {total_reevals/successful:.2f}\")\n",
    "\n",
    "print(\"âœ… Batch processing functions (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20b827",
   "metadata": {},
   "source": [
    "## 8. Execution Modes & Examples ğŸš€\n",
    "\n",
    "This section provides both single candidate evaluation and CSV batch processing examples. Choose the mode that fits your needs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd63db2",
   "metadata": {},
   "source": [
    "### 8.1 Single Candidate Mode ğŸ‘¤\n",
    "\n",
    "Run this section to evaluate a single candidate. Perfect for testing and individual assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ SINGLE CANDIDATE EVALUATION EXAMPLE\n",
    "# Modify these variables to test with your own candidate\n",
    "\n",
    "# Sample candidate information\n",
    "CANDIDATE_NAME = \"Sarah Chen\"\n",
    "CANDIDATE_PROFILE = \"\"\"\n",
    "Senior Software Engineer with 7 years of experience in full-stack development. \n",
    "Expertise in Python, JavaScript, React, and Django. Led a team of 5 developers \n",
    "in building scalable web applications. Strong background in cloud technologies \n",
    "(AWS, Docker) and agile methodologies. M.S. in Computer Science from Stanford University.\n",
    "Excellent communication skills and experience mentoring junior developers.\n",
    "\"\"\"\n",
    "\n",
    "JOB_REQUIREMENTS = \"\"\"\n",
    "We are seeking a Senior Full-Stack Developer to join our growing technology team. \n",
    "Requirements: 5+ years of experience in web development, proficiency in Python \n",
    "and JavaScript frameworks, experience with cloud platforms, strong problem-solving \n",
    "skills, and ability to work in a collaborative environment. Leadership experience \n",
    "and mentoring skills are highly valued.\n",
    "\"\"\"\n",
    "\n",
    "# Create candidate data object\n",
    "sample_candidate = CandidateData(\n",
    "    name=CANDIDATE_NAME,\n",
    "    profile=CANDIDATE_PROFILE,\n",
    "    job_requirements=JOB_REQUIREMENTS\n",
    ")\n",
    "\n",
    "print(f\"ğŸ¯ Prepared candidate for evaluation: {sample_candidate.name}\")\n",
    "print(f\"ğŸ“ Profile length: {len(CANDIDATE_PROFILE)} characters\")\n",
    "print(f\"ğŸ“‹ Job requirements length: {len(JOB_REQUIREMENTS)} characters\")\n",
    "\n",
    "# Validate environment before processing\n",
    "if not Config.validate_environment():\n",
    "    print(\"âŒ Environment validation failed. Please check your API key configuration.\")\n",
    "else:\n",
    "    print(\"âœ… Ready to process single candidate\")\n",
    "    print(\"Run the next cell to execute the evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ EXECUTE SINGLE CANDIDATE EVALUATION\n",
    "# Run this cell to process the candidate through the complete AI hiring workflow\n",
    "\n",
    "async def run_single_candidate_evaluation():\n",
    "    \"\"\"Execute single candidate evaluation with comprehensive reporting.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Starting single candidate evaluation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Process the candidate through the workflow\n",
    "        result = await hiring_workflow.process_candidate(sample_candidate)\n",
    "        \n",
    "        # Display comprehensive results\n",
    "        print(\"\\nğŸ“Š EVALUATION RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ‘¤ Candidate: {result['candidate_name']}\")\n",
    "        print(f\"ğŸ¯ Decision: {result['decision'].upper()}\")\n",
    "        print(f\"ğŸ“ˆ Confidence: {result['confidence_score']:.2f}\")\n",
    "        print(f\"ğŸ›¡ï¸  Bias Status: {result['bias_detected']}\")\n",
    "        print(f\"ğŸ” Bias Confidence: {result['bias_confidence']:.2f}\")\n",
    "        print(f\"ğŸ”„ Re-evaluations: {result['re_evaluation_count']}\")\n",
    "        print(f\"â±ï¸  Processing Time: {result['processing_duration']:.2f}s\")\n",
    "        print(f\"âŒ Errors: {'Yes' if result['error_occurred'] else 'No'}\")\n",
    "        \n",
    "        if result['error_occurred']:\n",
    "            print(f\"âš ï¸  Error Message: {result['error_message']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’­ DECISION REASONING:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result['decision_reasoning'])\n",
    "        \n",
    "        print(f\"\\nğŸ” BIAS ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(result['bias_reasoning'])\n",
    "        \n",
    "        if result['re_evaluation_history']:\n",
    "            print(f\"\\nğŸ“ RE-EVALUATION HISTORY:\")\n",
    "            print(\"-\" * 40)\n",
    "            for i, evaluation in enumerate(result['re_evaluation_history'], 1):\n",
    "                print(f\"Round {i}: {evaluation['bias_detected']} (confidence: {evaluation['bias_confidence']:.2f})\")\n",
    "        \n",
    "        # Rate limiter status\n",
    "        rate_status = rate_limiter.get_current_usage()\n",
    "        print(f\"\\nğŸš¦ RATE LIMITER STATUS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Current usage: {rate_status['current_requests']}/{rate_status['max_requests']} requests\")\n",
    "        print(f\"Usage percentage: {rate_status['usage_percentage']:.1f}%\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during single candidate evaluation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the evaluation\n",
    "print(\"â³ Starting evaluation (this may take 30-60 seconds)...\")\n",
    "single_result = await run_single_candidate_evaluation()\n",
    "\n",
    "if single_result:\n",
    "    print(\"\\nâœ… Single candidate evaluation completed successfully!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Single candidate evaluation failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0716eae",
   "metadata": {},
   "source": [
    "### 8.2 CSV Batch Processing Mode ğŸ“Š\n",
    "\n",
    "Process multiple candidates from a CSV file. Perfect for handling large-scale hiring evaluations with comprehensive results export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f90bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š CSV BATCH PROCESSING CONFIGURATION\n",
    "# Configure these variables for your batch processing needs\n",
    "\n",
    "# CSV file path (update this path to your CSV file)\n",
    "CSV_FILE_PATH = \"sample-data.csv\"  # Update this to your CSV file path\n",
    "\n",
    "# Job requirements for all candidates in the batch\n",
    "BATCH_JOB_REQUIREMENTS = \"\"\"\n",
    "Senior Software Developer Position - Remote/Hybrid\n",
    "We are seeking an experienced software developer to join our innovative team.\n",
    "\n",
    "Requirements:\n",
    "- 3+ years of software development experience\n",
    "- Proficiency in modern programming languages (Python, JavaScript, Java, etc.)\n",
    "- Experience with web frameworks and databases\n",
    "- Strong problem-solving and analytical skills\n",
    "- Excellent communication and teamwork abilities\n",
    "- Bachelor's degree in Computer Science or related field (preferred)\n",
    "\n",
    "Responsibilities:\n",
    "- Design and develop scalable software solutions\n",
    "- Collaborate with cross-functional teams\n",
    "- Participate in code reviews and technical discussions\n",
    "- Mentor junior developers\n",
    "- Stay current with emerging technologies\n",
    "\n",
    "We offer competitive compensation, flexible work arrangements, and opportunities for professional growth.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“Š CSV Batch Processing Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ CSV File: {CSV_FILE_PATH}\")\n",
    "print(f\"ğŸ“‹ Job Requirements Length: {len(BATCH_JOB_REQUIREMENTS)} characters\")\n",
    "print(f\"âš™ï¸  Batch Size: {Config.BATCH_SIZE} candidates per batch\")\n",
    "print(f\"ğŸš¦ Rate Limit: {Config.MAX_REQUESTS_PER_MINUTE} requests/minute\")\n",
    "\n",
    "# Check if CSV file exists\n",
    "if os.path.exists(CSV_FILE_PATH):\n",
    "    print(f\"âœ… CSV file found: {CSV_FILE_PATH}\")\n",
    "    \n",
    "    # Preview CSV structure\n",
    "    try:\n",
    "        preview_df = pd.read_csv(CSV_FILE_PATH, nrows=3)\n",
    "        print(f\"ğŸ“Š CSV Columns: {list(preview_df.columns)}\")\n",
    "        print(f\"ğŸ“ˆ Preview rows: {len(preview_df)}\")\n",
    "        print(\"\\nğŸ“ First few rows:\")\n",
    "        print(preview_df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error reading CSV preview: {e}\")\n",
    "else:\n",
    "    print(f\"âŒ CSV file not found: {CSV_FILE_PATH}\")\n",
    "    print(\"ğŸ“ Please ensure your CSV file exists and update the CSV_FILE_PATH variable\")\n",
    "    print(\"ğŸ’¡ Expected CSV format: columns named 'name' and 'profile' (or similar)\")\n",
    "\n",
    "print(\"\\nâœ… Configuration complete. Run the next cell to start batch processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ EXECUTE CSV BATCH PROCESSING\n",
    "# Run this cell to process all candidates from the CSV file\n",
    "\n",
    "async def run_csv_batch_processing():\n",
    "    \"\"\"Execute comprehensive CSV batch processing with full reporting.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Starting CSV Batch Processing...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Validate environment\n",
    "        if not Config.validate_environment():\n",
    "            print(\"âŒ Environment validation failed. Cannot proceed.\")\n",
    "            return None\n",
    "        \n",
    "        # Load candidates from CSV\n",
    "        print(\"ğŸ“ Loading candidates from CSV...\")\n",
    "        candidates = batch_processor.load_candidates_from_csv(\n",
    "            CSV_FILE_PATH, \n",
    "            BATCH_JOB_REQUIREMENTS\n",
    "        )\n",
    "        \n",
    "        if not candidates:\n",
    "            print(\"âŒ No valid candidates found in CSV file.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"âœ… Loaded {len(candidates)} candidates for processing\")\n",
    "        \n",
    "        # Process all candidates\n",
    "        print(\"\\nğŸ”„ Starting batch processing...\")\n",
    "        results = await batch_processor.process_batch(candidates)\n",
    "        \n",
    "        # Display comprehensive results summary\n",
    "        print(\"\\nğŸ“Š BATCH PROCESSING RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Processing statistics\n",
    "        stats = batch_processor.processing_stats\n",
    "        print(f\"ğŸ“ˆ Total Candidates: {stats['total_candidates']}\")\n",
    "        print(f\"âœ… Successfully Processed: {stats['processed_successfully']}\")\n",
    "        print(f\"âŒ Failed Processing: {stats['failed_processing']}\")\n",
    "        print(f\"ğŸ“Š Success Rate: {(stats['processed_successfully']/stats['total_candidates']*100):.1f}%\")\n",
    "        print(f\"â±ï¸  Total Processing Time: {stats['total_processing_time']:.2f}s\")\n",
    "        print(f\"âš¡ Average Time per Candidate: {stats['average_processing_time']:.2f}s\")\n",
    "        \n",
    "        # Decision distribution\n",
    "        successful_results = [r for r in results if not r[\"error_occurred\"]]\n",
    "        if successful_results:\n",
    "            decisions = [r[\"decision\"] for r in successful_results]\n",
    "            decision_counts = pd.Series(decisions).value_counts()\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ DECISION DISTRIBUTION:\")\n",
    "            print(\"-\" * 40)\n",
    "            for decision, count in decision_counts.items():\n",
    "                percentage = (count / len(successful_results)) * 100\n",
    "                print(f\"{decision.upper()}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Bias detection summary\n",
    "        if successful_results:\n",
    "            bias_states = [r[\"bias_detected\"] for r in successful_results]\n",
    "            bias_counts = pd.Series(bias_states).value_counts()\n",
    "            \n",
    "            print(f\"\\nğŸ›¡ï¸  BIAS DETECTION SUMMARY:\")\n",
    "            print(\"-\" * 40)\n",
    "            for bias_state, count in bias_counts.items():\n",
    "                percentage = (count / len(successful_results)) * 100\n",
    "                print(f\"{bias_state.upper()}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Re-evaluation statistics\n",
    "        re_evaluations = [r[\"re_evaluation_count\"] for r in successful_results]\n",
    "        if re_evaluations:\n",
    "            total_re_evals = sum(re_evaluations)\n",
    "            avg_re_evals = total_re_evals / len(re_evaluations)\n",
    "            max_re_evals = max(re_evaluations)\n",
    "            \n",
    "            print(f\"\\nğŸ”„ RE-EVALUATION STATISTICS:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"Total re-evaluations: {total_re_evals}\")\n",
    "            print(f\"Average per candidate: {avg_re_evals:.2f}\")\n",
    "            print(f\"Maximum re-evaluations: {max_re_evals}\")\n",
    "        \n",
    "        # Error summary\n",
    "        error_results = [r for r in results if r[\"error_occurred\"]]\n",
    "        if error_results:\n",
    "            print(f\"\\nâŒ ERROR SUMMARY:\")\n",
    "            print(\"-\" * 40)\n",
    "            for error_result in error_results[:5]:  # Show first 5 errors\n",
    "                print(f\"â€¢ {error_result['candidate_name']}: {error_result['error_message'][:100]}...\")\n",
    "            \n",
    "            if len(error_results) > 5:\n",
    "                print(f\"... and {len(error_results) - 5} more errors\")\n",
    "        \n",
    "        # Export results\n",
    "        print(f\"\\nğŸ’¾ EXPORTING RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        exported_files = batch_processor.export_results()\n",
    "        \n",
    "        if exported_files:\n",
    "            for file_type, file_path in exported_files.items():\n",
    "                print(f\"âœ… {file_type.upper()}: {file_path}\")\n",
    "        \n",
    "        # Rate limiter final status\n",
    "        rate_status = rate_limiter.get_current_usage()\n",
    "        print(f\"\\nğŸš¦ FINAL RATE LIMITER STATUS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Current usage: {rate_status['current_requests']}/{rate_status['max_requests']} requests\")\n",
    "        print(f\"Usage percentage: {rate_status['usage_percentage']:.1f}%\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Critical error during batch processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Check if CSV file exists before processing\n",
    "if os.path.exists(CSV_FILE_PATH):\n",
    "    print(f\"â³ Starting batch processing for {CSV_FILE_PATH}...\")\n",
    "    print(\"ğŸ“ This may take several minutes depending on the number of candidates...\")\n",
    "    print(\"ğŸš¦ Processing is rate-limited to comply with API restrictions...\")\n",
    "    \n",
    "    # Execute batch processing\n",
    "    batch_results = await run_csv_batch_processing()\n",
    "    \n",
    "    if batch_results:\n",
    "        print(f\"\\nğŸ‰ CSV batch processing completed successfully!\")\n",
    "        print(f\"ğŸ“Š Processed {len(batch_results)} candidates\")\n",
    "        print(f\"ğŸ“ Results exported to the 'results' directory\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ CSV batch processing failed!\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ Cannot start batch processing: CSV file '{CSV_FILE_PATH}' not found\")\n",
    "    print(\"ğŸ“ Please update CSV_FILE_PATH with the correct path to your CSV file\")\n",
    "    print(\"ğŸ’¡ Expected CSV format: columns named 'name' and 'profile' (or similar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c6736",
   "metadata": {},
   "source": [
    "## 9. System Overview & Usage Guide ğŸ“‹\n",
    "\n",
    "### ğŸ¯ **Multi-Agent AI Hiring System - Complete Production Implementation**\n",
    "\n",
    "This notebook provides a comprehensive, production-ready implementation of a Multi-Agent AI Hiring System using **LangGraph** and **Google Gemini AI**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ—ï¸ **System Architecture**\n",
    "\n",
    "**Core Components:**\n",
    "- **ğŸ¤– Job Matching Agent**: Evaluates candidates against job requirements with detailed scoring\n",
    "- **ğŸ›¡ï¸ Bias Classification Agent**: Detects and mitigates hiring bias for fair evaluation\n",
    "- **ğŸ”„ LangGraph Workflow**: Orchestrates agent interactions with automatic re-evaluation loops\n",
    "- **ğŸš¦ Rate Limiter**: Ensures API compliance with intelligent throttling\n",
    "- **ğŸ“Š Batch Processor**: Handles large-scale CSV processing with progress tracking\n",
    "\n",
    "---\n",
    "\n",
    "### âš¡ **Key Features**\n",
    "\n",
    "**Production-Ready Capabilities:**\n",
    "- âœ… **Comprehensive Error Handling**: Graceful failure recovery with detailed logging\n",
    "- âœ… **Rate Limiting & Retry Logic**: API-compliant with exponential backoff\n",
    "- âœ… **State Management**: Type-safe state transitions with validation\n",
    "- âœ… **Bias Detection & Re-evaluation**: Automatic fairness enforcement\n",
    "- âœ… **Batch Processing**: High-throughput CSV processing with progress tracking\n",
    "- âœ… **Multi-format Export**: CSV, JSON, and summary report generation\n",
    "- âœ… **Thread-safe Operations**: Concurrent processing with safety guarantees\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ **Usage Instructions**\n",
    "\n",
    "**1. Environment Setup:**\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Set up environment variables\n",
    "GOOGLE_API_KEY=your_gemini_api_key_here\n",
    "```\n",
    "\n",
    "**2. Single Candidate Evaluation:**\n",
    "- Modify candidate information in Section 8.1\n",
    "- Run the single candidate evaluation cell\n",
    "- Review comprehensive results and bias analysis\n",
    "\n",
    "**3. CSV Batch Processing:**\n",
    "- Prepare CSV file with 'name' and 'profile' columns\n",
    "- Update CSV_FILE_PATH in Section 8.2\n",
    "- Run batch processing for large-scale evaluation\n",
    "- Check 'results' directory for exported files\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š **Expected Output Files**\n",
    "\n",
    "**Batch Processing Exports:**\n",
    "- `hiring_results_YYYYMMDD_HHMMSS.csv` - Structured results data\n",
    "- `hiring_results_YYYYMMDD_HHMMSS.json` - Complete processing metadata\n",
    "- `hiring_summary_YYYYMMDD_HHMMSS.txt` - Human-readable summary report\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ **Configuration Options**\n",
    "\n",
    "**Customizable Settings (in Config class):**\n",
    "- `MODEL_NAME`: Google Gemini model selection\n",
    "- `MAX_RE_EVALUATIONS`: Bias-triggered re-evaluation limit  \n",
    "- `MAX_REQUESTS_PER_MINUTE`: API rate limiting\n",
    "- `BATCH_SIZE`: Concurrent processing batch size\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ›¡ï¸ **Bias Detection Framework**\n",
    "\n",
    "**Detected Bias Types:**\n",
    "- **Demographic Bias**: Age, gender, race, educational prestige\n",
    "- **Cognitive Bias**: Halo effect, confirmation bias, similarity bias\n",
    "- **Structural Bias**: Career path preferences, unrealistic requirements\n",
    "- **Communication Bias**: Language and cultural preferences\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ˆ **Performance Characteristics**\n",
    "\n",
    "**Processing Speed:**\n",
    "- Single candidate: ~30-60 seconds (including bias detection)\n",
    "- Batch processing: ~1-2 minutes per candidate (rate-limited)\n",
    "- Concurrent processing within rate limits for optimal throughput\n",
    "\n",
    "**Accuracy Features:**\n",
    "- Multi-criteria evaluation framework\n",
    "- Confidence scoring for all decisions\n",
    "- Comprehensive bias detection with re-evaluation\n",
    "- Error handling with conservative defaults\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ **Troubleshooting**\n",
    "\n",
    "**Common Issues:**\n",
    "- **API Key Error**: Ensure GOOGLE_API_KEY is set correctly\n",
    "- **Rate Limiting**: System automatically handles API limits\n",
    "- **CSV Format**: Ensure 'name' and 'profile' columns exist\n",
    "- **Memory Usage**: Large batches are automatically chunked\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ **Next Steps**\n",
    "\n",
    "1. **Test with Sample Data**: Run single candidate evaluation first\n",
    "2. **Prepare Your CSV**: Format your candidate data appropriately  \n",
    "3. **Configure Job Requirements**: Update job descriptions for your needs\n",
    "4. **Execute Batch Processing**: Process your candidate pipeline\n",
    "5. **Analyze Results**: Review exported reports and bias statistics\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Your Multi-Agent AI Hiring System is ready for production use!**\n",
    "\n",
    "*Built with LangGraph, Google Gemini AI, and production-grade best practices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb9aaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Workflow creation functions (exact source code) loaded\n",
      "âœ… create_hiring_workflow function ready\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ï¸ Workflow Creation - From source code (src/main.py)\n",
    "\n",
    "def job_matching_node(state: HiringState) -> dict:\n",
    "    \"\"\"Node for making hiring decisions.\"\"\"\n",
    "    logger.info(\"---Job Matching Agent---\")\n",
    "    \n",
    "    try:\n",
    "        agent = JobMatchingAgent()\n",
    "        \n",
    "        # Check for previous feedback\n",
    "        re_evaluation_count = state.get(\"re_evaluation_count\", 0)\n",
    "        bias_feedback = state.get(\"bias_feedback\", \"\")\n",
    "        \n",
    "        # Build context for the agent\n",
    "        context = {\n",
    "            \"Resume\": state[\"Resume\"],\n",
    "            \"Job_Description\": state[\"Job_Description\"],\n",
    "            \"Transcript\": state[\"Transcript\"],\n",
    "            \"Role\": state[\"Role\"],\n",
    "            \"re_evaluation_count\": re_evaluation_count,\n",
    "            \"bias_feedback\": bias_feedback\n",
    "        }\n",
    "        \n",
    "        # Get decision from agent\n",
    "        result = agent.evaluate(context)\n",
    "        \n",
    "        logger.info(f\"Job matching result: {result.get('decision', 'unknown')}\")\n",
    "        \n",
    "        # Add to evaluation insights\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        insight = {\n",
    "            \"evaluation_number\": re_evaluation_count + 1,\n",
    "            \"is_re_evaluation\": re_evaluation_count > 0,\n",
    "            \"decision\": result.get(\"decision\", \"unknown\"),\n",
    "            \"primary_reason\": result.get(\"primary_reason\", \"\"),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        evaluation_insights.append(insight)\n",
    "        \n",
    "        # Return result with insights\n",
    "        result[\"evaluation_insights\"] = evaluation_insights\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Job matching error: {e}\")\n",
    "        return {\n",
    "            \"decision\": \"reject\",\n",
    "            \"primary_reason\": f\"Processing error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def bias_classification_node(state: HiringState) -> dict:\n",
    "    \"\"\"Node for bias classification.\"\"\"\n",
    "    logger.info(\"---Bias Classification Agent---\")\n",
    "    \n",
    "    try:\n",
    "        agent = BiasClassificationAgent()\n",
    "        \n",
    "        # Build context for bias analysis\n",
    "        context = {\n",
    "            \"Resume\": state[\"Resume\"],\n",
    "            \"Job_Description\": state[\"Job_Description\"],\n",
    "            \"Transcript\": state[\"Transcript\"],\n",
    "            \"Role\": state[\"Role\"],\n",
    "            \"decision\": state.get(\"decision\", \"unknown\"),\n",
    "            \"primary_reason\": state.get(\"primary_reason\", \"\")\n",
    "        }\n",
    "        \n",
    "        # Get bias classification\n",
    "        result = agent.evaluate(context)\n",
    "        \n",
    "        logger.info(f\"Bias classification: {result.get('bias_classification', 'unknown')}\")\n",
    "        \n",
    "        # Update the latest evaluation insight with classification\n",
    "        evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "        if evaluation_insights:\n",
    "            latest_insight = evaluation_insights[-1]\n",
    "            latest_insight[\"classification\"] = result.get(\"bias_classification\", \"unknown\")\n",
    "            latest_insight[\"bias_reason\"] = result.get(\"bias_reason\", \"\")\n",
    "        \n",
    "        result[\"evaluation_insights\"] = evaluation_insights\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Bias classification error: {e}\")\n",
    "        return {\n",
    "            \"bias_classification\": \"error\",\n",
    "            \"bias_reason\": f\"Processing error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def should_continue(state: HiringState) -> str:\n",
    "    \"\"\"Determine whether to continue with re-evaluation or finalize.\"\"\"\n",
    "    bias_classification = state.get(\"bias_classification\", \"unbiased\")\n",
    "    re_evaluation_count = state.get(\"re_evaluation_count\", 0)\n",
    "    \n",
    "    # Check if bias detected and haven't exceeded max re-evaluations\n",
    "    if bias_classification == \"biased\" and re_evaluation_count < Config.MAX_RE_EVALUATIONS:\n",
    "        logger.info(f\"Bias detected, triggering re-evaluation #{re_evaluation_count + 1}\")\n",
    "        return \"re_evaluate\"\n",
    "    else:\n",
    "        logger.info(\"Proceeding to finalization\")\n",
    "        return \"finalize\"\n",
    "\n",
    "def re_evaluate_node(state: HiringState) -> dict:\n",
    "    \"\"\"Handle re-evaluation trigger.\"\"\"\n",
    "    logger.info(\"---Re-evaluation Trigger---\")\n",
    "    \n",
    "    count = state.get(\"re_evaluation_count\", 0) + 1\n",
    "    bias_feedback = state.get(\"bias_feedback\", \"\")\n",
    "    logger.info(f\"Re-evaluation #{count} triggered by bias detection\")\n",
    "    \n",
    "    # The bias_feedback is already in state from bias classification node\n",
    "    # We need to ensure it persists through the re-evaluation\n",
    "    result = {\n",
    "        \"re_evaluation_count\": count\n",
    "    }\n",
    "    \n",
    "    # Explicitly preserve bias_feedback if it exists\n",
    "    if bias_feedback:\n",
    "        result[\"bias_feedback\"] = bias_feedback\n",
    "    \n",
    "    return result\n",
    "\n",
    "def finalize_node(state: HiringState) -> dict:\n",
    "    \"\"\"Finalize the hiring decision.\"\"\"\n",
    "    logger.info(\"---Finalizing Decision---\")\n",
    "    \n",
    "    decision = state.get(\"decision\", \"reject\")\n",
    "    bias_classification = state.get(\"bias_classification\", \"unbiased\")\n",
    "    re_evaluations = state.get(\"re_evaluation_count\", 0)\n",
    "    evaluation_insights = state.get(\"evaluation_insights\", [])\n",
    "    \n",
    "    logger.info(f\"Final Decision: {decision}\")\n",
    "    logger.info(f\"Bias Classification: {bias_classification}\")\n",
    "    logger.info(f\"Re-evaluations: {re_evaluations}\")\n",
    "    \n",
    "    # Log evaluation insights summary\n",
    "    if evaluation_insights:\n",
    "        logger.info(\"ğŸ“Š Evaluation Insights:\")\n",
    "        for insight in evaluation_insights:\n",
    "            eval_type = \"re-evaluation\" if insight.get(\"is_re_evaluation\") else \"initial\"\n",
    "            logger.info(f\"  {eval_type} #{insight['evaluation_number']}: {insight['decision']} â†’ {insight.get('classification', 'pending')}\")\n",
    "    \n",
    "    return {\n",
    "        \"process_complete\": True,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"evaluation_insights\": evaluation_insights\n",
    "    }\n",
    "\n",
    "def create_hiring_workflow():\n",
    "    \"\"\"Create and return the hiring workflow graph.\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(HiringState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"job_matcher\", job_matching_node)\n",
    "    workflow.add_node(\"bias_classifier\", bias_classification_node)\n",
    "    workflow.add_node(\"re_evaluate\", re_evaluate_node)\n",
    "    workflow.add_node(\"finalize\", finalize_node)\n",
    "    \n",
    "    # Add edges - cleaner flow\n",
    "    workflow.add_edge(START, \"job_matcher\")\n",
    "    workflow.add_edge(\"job_matcher\", \"bias_classifier\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"bias_classifier\", \n",
    "        should_continue,\n",
    "        {\n",
    "            \"re_evaluate\": \"re_evaluate\",\n",
    "            \"finalize\": \"finalize\"\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"re_evaluate\", \"job_matcher\")\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    # Add memory\n",
    "    memory = InMemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "print(\"ğŸ—ï¸ Workflow creation functions (exact source code) loaded\")\n",
    "print(\"âœ… create_hiring_workflow function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074344af",
   "metadata": {},
   "source": [
    "## 5. Intelligent Agent Implementations ğŸ¤–\n",
    "\n",
    "This section implements the core AI agents: Job Matching Agent for candidate evaluation and Bias Classification Agent for fairness validation, both with advanced prompt engineering and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcc3d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Job Matching Agent initialized with optimized prompts\n",
      "âœ… Job Matching Agent ready for candidate evaluation\n"
     ]
    }
   ],
   "source": [
    "class JobMatchingAgent:\n",
    "    \"\"\"\n",
    "    Advanced job matching agent with sophisticated prompt engineering.\n",
    "    Evaluates candidate-job fit with detailed reasoning and confidence scoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_config: Dict[str, Any]):\n",
    "        self.llm = ChatGoogleGenerativeAI(**model_config)\n",
    "        self.prompt_template = self._create_prompt_template()\n",
    "        self.chain = self.prompt_template | self.llm | StrOutputParser()\n",
    "        \n",
    "        print(\"ğŸ¤– Job Matching Agent initialized with optimized prompts\")\n",
    "    \n",
    "    def _create_prompt_template(self) -> ChatPromptTemplate:\n",
    "        \"\"\"Create sophisticated prompt template with advanced reasoning.\"\"\"\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert HR professional and technical recruiter with 15+ years of experience in talent acquisition. Your role is to evaluate candidate-job fit with precision, objectivity, and detailed analysis.\n",
    "\n",
    "EVALUATION FRAMEWORK:\n",
    "1. Technical Skills Assessment (40% weight)\n",
    "   - Core competency alignment\n",
    "   - Skill depth vs. breadth analysis\n",
    "   - Technology stack compatibility\n",
    "   - Learning curve assessment\n",
    "\n",
    "2. Experience Relevance (35% weight)\n",
    "   - Industry experience alignment\n",
    "   - Role complexity comparison\n",
    "   - Project scale and impact\n",
    "   - Leadership and collaboration evidence\n",
    "\n",
    "3. Educational Background (15% weight)\n",
    "   - Degree relevance and level\n",
    "   - Specialized certifications\n",
    "   - Continuous learning indicators\n",
    "   - Academic achievement context\n",
    "\n",
    "4. Cultural and Role Fit (10% weight)\n",
    "   - Career trajectory alignment\n",
    "   - Growth potential assessment\n",
    "   - Team dynamic compatibility\n",
    "   - Long-term retention likelihood\n",
    "\n",
    "DECISION CRITERIA:\n",
    "- HIRE: 80%+ overall fit, strong in 3+ categories, no critical gaps\n",
    "- REJECT: <60% overall fit, critical gaps in core requirements\n",
    "- PENDING: 60-79% fit, promising but needs clarification/development\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Decision: [hire/reject/pending]\n",
    "Confidence: [0.0-1.0]\n",
    "Reasoning: [Detailed 3-4 sentence analysis covering key factors]\n",
    "\n",
    "Be thorough, objective, and provide actionable insights.\"\"\"),\n",
    "            \n",
    "            (\"human\", \"\"\"Please evaluate this candidate for the given position:\n",
    "\n",
    "CANDIDATE PROFILE:\n",
    "Name: {candidate_name}\n",
    "Skills: {candidate_skills}\n",
    "Experience: {candidate_experience}\n",
    "Education: {candidate_education}\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "Position: {job_title}\n",
    "Required Skills: {required_skills}\n",
    "Experience Level: {experience_level}\n",
    "Education Requirements: {education_requirements}\n",
    "\n",
    "Provide your comprehensive evaluation following the framework above.\"\"\")\n",
    "        ])\n",
    "    \n",
    "    async def evaluate_candidate(self, state: HiringState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Comprehensive candidate evaluation with error handling and validation.\n",
    "        Returns structured decision with confidence scoring.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Apply rate limiting\n",
    "            rate_limiter.wait_if_needed()\n",
    "            \n",
    "            # Prepare input data\n",
    "            input_data = {\n",
    "                \"candidate_name\": state[\"candidate\"].name,\n",
    "                \"candidate_skills\": state[\"candidate\"].skills,\n",
    "                \"candidate_experience\": state[\"candidate\"].experience,\n",
    "                \"candidate_education\": state[\"candidate\"].education,\n",
    "                \"job_title\": state[\"job_requirements\"].title,\n",
    "                \"required_skills\": state[\"job_requirements\"].required_skills,\n",
    "                \"experience_level\": state[\"job_requirements\"].experience_level,\n",
    "                \"education_requirements\": state[\"job_requirements\"].education_requirements\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ” Evaluating candidate: {state['candidate'].name}\")\n",
    "            print(f\"ğŸ’¼ Position: {state['job_requirements'].title}\")\n",
    "            \n",
    "            # Execute evaluation with retry logic\n",
    "            response = await retry_handler.execute_with_retry(\n",
    "                self.chain.ainvoke, input_data\n",
    "            )\n",
    "            \n",
    "            # Parse response with robust error handling\n",
    "            decision, confidence, reasoning = self._parse_response(response)\n",
    "            \n",
    "            print(f\"âœ… Evaluation complete: {decision} (confidence: {confidence:.2f})\")\n",
    "            \n",
    "            return {\n",
    "                \"decision\": decision,\n",
    "                \"reasoning\": reasoning,\n",
    "                \"confidence_score\": confidence,\n",
    "                \"agent_name\": \"JobMatchingAgent\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Job matching evaluation error: {e}\")\n",
    "            return {\n",
    "                \"decision\": Config.DEFAULT_DECISION_ON_ERROR,\n",
    "                \"reasoning\": f\"Evaluation failed due to technical error: {str(e)}. Defaulting to conservative decision.\",\n",
    "                \"confidence_score\": 0.0,\n",
    "                \"agent_name\": \"JobMatchingAgent\"\n",
    "            }\n",
    "    \n",
    "    def _parse_response(self, response: str) -> Tuple[str, float, str]:\n",
    "        \"\"\"\n",
    "        Robust response parsing with fallback handling.\n",
    "        Extracts decision, confidence, and reasoning from LLM output.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lines = response.strip().split('\\n')\n",
    "            decision = \"pending\"\n",
    "            confidence = 0.5\n",
    "            reasoning = \"Standard evaluation completed\"\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip().lower()\n",
    "                \n",
    "                # Extract decision\n",
    "                if line.startswith('decision:'):\n",
    "                    decision_text = line.split(':', 1)[1].strip()\n",
    "                    if any(word in decision_text for word in ['hire', 'accept']):\n",
    "                        decision = \"hire\"\n",
    "                    elif any(word in decision_text for word in ['reject', 'decline']):\n",
    "                        decision = \"reject\"\n",
    "                    else:\n",
    "                        decision = \"pending\"\n",
    "                \n",
    "                # Extract confidence\n",
    "                elif line.startswith('confidence:'):\n",
    "                    try:\n",
    "                        conf_text = line.split(':', 1)[1].strip()\n",
    "                        # Handle various confidence formats\n",
    "                        if conf_text.endswith('%'):\n",
    "                            confidence = float(conf_text[:-1]) / 100\n",
    "                        else:\n",
    "                            confidence = float(conf_text)\n",
    "                        confidence = max(0.0, min(1.0, confidence))  # Clamp to [0,1]\n",
    "                    except (ValueError, IndexError):\n",
    "                        confidence = 0.5\n",
    "                \n",
    "                # Extract reasoning\n",
    "                elif line.startswith('reasoning:'):\n",
    "                    reasoning = line.split(':', 1)[1].strip()\n",
    "            \n",
    "            # If reasoning not found in expected format, use full response\n",
    "            if reasoning == \"Standard evaluation completed\" and len(response) > 50:\n",
    "                reasoning = response[:200] + \"...\" if len(response) > 200 else response\n",
    "            \n",
    "            return decision, confidence, reasoning\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Response parsing error: {e}\")\n",
    "            return Config.DEFAULT_DECISION_ON_ERROR, 0.0, f\"Response parsing failed: {str(e)}\"\n",
    "\n",
    "# Initialize job matching agent\n",
    "job_matching_agent = JobMatchingAgent(Config.get_model_config())\n",
    "print(\"âœ… Job Matching Agent ready for candidate evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d63f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Bias Classification Agent initialized with ethical AI framework\n",
      "âœ… Bias Classification Agent ready for fairness analysis\n"
     ]
    }
   ],
   "source": [
    "class BiasClassificationAgent:\n",
    "    \"\"\"\n",
    "    Advanced bias detection agent with comprehensive fairness analysis.\n",
    "    Identifies potential bias in hiring decisions using ethical AI frameworks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_config: Dict[str, Any]):\n",
    "        self.llm = ChatGoogleGenerativeAI(**model_config)\n",
    "        self.prompt_template = self._create_bias_detection_prompt()\n",
    "        self.chain = self.prompt_template | self.llm | StrOutputParser()\n",
    "        \n",
    "        print(\"ğŸ›¡ï¸ Bias Classification Agent initialized with ethical AI framework\")\n",
    "    \n",
    "    def _create_bias_detection_prompt(self) -> ChatPromptTemplate:\n",
    "        \"\"\"Create specialized prompt for bias detection and fairness analysis.\"\"\"\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert in ethical AI, diversity & inclusion, and fair hiring practices. Your role is to analyze hiring decisions for potential bias and ensure equitable treatment of all candidates.\n",
    "\n",
    "BIAS DETECTION FRAMEWORK:\n",
    "\n",
    "1. DEMOGRAPHIC BIAS INDICATORS:\n",
    "   - Age-related assumptions or preferences\n",
    "   - Gender-based role stereotyping\n",
    "   - Educational institution prestige bias\n",
    "   - Geographic or cultural background bias\n",
    "   - Name-based assumptions about identity\n",
    "\n",
    "2. COGNITIVE BIAS PATTERNS:\n",
    "   - Halo/Horn effect (over-weighting single factors)\n",
    "   - Confirmation bias (seeking supporting evidence)\n",
    "   - Similarity bias (preference for similar backgrounds)\n",
    "   - Anchoring bias (over-reliance on first impressions)\n",
    "   - Availability bias (recent examples influencing decisions)\n",
    "\n",
    "3. STRUCTURAL BIAS ANALYSIS:\n",
    "   - Inconsistent evaluation criteria application\n",
    "   - Disproportionate weight on non-essential factors\n",
    "   - Double standards in requirement interpretation\n",
    "   - Lack of objective, measurable criteria\n",
    "   - Cultural fit coded language\n",
    "\n",
    "4. FAIRNESS VALIDATION:\n",
    "   - Merit-based evaluation focus\n",
    "   - Consistent criteria application\n",
    "   - Objective skill and experience assessment\n",
    "   - Job-relevant factor prioritization\n",
    "   - Equal opportunity consideration\n",
    "\n",
    "CLASSIFICATION CRITERIA:\n",
    "- BIASED: Clear evidence of unfair treatment or discriminatory reasoning\n",
    "- UNBIASED: Fair, merit-based evaluation with consistent criteria\n",
    "- UNCERTAIN: Mixed signals requiring additional review or clarification\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Classification: [biased/unbiased/uncertain]\n",
    "Confidence: [0.0-1.0]\n",
    "Analysis: [2-3 sentence explanation of bias assessment]\n",
    "\n",
    "Focus on fairness, objectivity, and protecting candidate rights.\"\"\"),\n",
    "            \n",
    "            (\"human\", \"\"\"Analyze this hiring decision for potential bias:\n",
    "\n",
    "CANDIDATE INFORMATION:\n",
    "Name: {candidate_name}\n",
    "Skills: {candidate_skills}\n",
    "Experience: {candidate_experience}\n",
    "Education: {candidate_education}\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "Position: {job_title}\n",
    "Required Skills: {required_skills}\n",
    "Experience Level: {experience_level}\n",
    "Education Requirements: {education_requirements}\n",
    "\n",
    "HIRING DECISION DETAILS:\n",
    "Decision: {decision}\n",
    "Reasoning: {reasoning}\n",
    "Confidence: {confidence}\n",
    "\n",
    "Please analyze this decision for bias using the framework above and provide your assessment.\"\"\")\n",
    "        ])\n",
    "    \n",
    "    async def analyze_bias(self, state: HiringState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Comprehensive bias analysis with detailed fairness evaluation.\n",
    "        Returns structured bias assessment with recommendations.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Apply rate limiting\n",
    "            rate_limiter.wait_if_needed()\n",
    "            \n",
    "            # Prepare input data for bias analysis\n",
    "            input_data = {\n",
    "                \"candidate_name\": state[\"candidate\"].name,\n",
    "                \"candidate_skills\": state[\"candidate\"].skills,\n",
    "                \"candidate_experience\": state[\"candidate\"].experience,\n",
    "                \"candidate_education\": state[\"candidate\"].education,\n",
    "                \"job_title\": state[\"job_requirements\"].title,\n",
    "                \"required_skills\": state[\"job_requirements\"].required_skills,\n",
    "                \"experience_level\": state[\"job_requirements\"].experience_level,\n",
    "                \"education_requirements\": state[\"job_requirements\"].education_requirements,\n",
    "                \"decision\": state[\"decision\"],\n",
    "                \"reasoning\": state[\"reasoning\"],\n",
    "                \"confidence\": state[\"confidence_score\"]\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ›¡ï¸ Analyzing decision for bias: {state['candidate'].name}\")\n",
    "            print(f\"âš–ï¸ Decision under review: {state['decision']}\")\n",
    "            \n",
    "            # Execute bias analysis with retry logic\n",
    "            response = await retry_handler.execute_with_retry(\n",
    "                self.chain.ainvoke, input_data\n",
    "            )\n",
    "            \n",
    "            # Parse bias analysis response\n",
    "            classification, confidence, analysis = self._parse_bias_response(response)\n",
    "            \n",
    "            print(f\"âœ… Bias analysis complete: {classification} (confidence: {confidence:.2f})\")\n",
    "            \n",
    "            return {\n",
    "                \"bias_assessment\": classification,\n",
    "                \"bias_reasoning\": analysis,\n",
    "                \"bias_confidence\": confidence,\n",
    "                \"agent_name\": \"BiasClassificationAgent\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Bias analysis error: {e}\")\n",
    "            return {\n",
    "                \"bias_assessment\": Config.DEFAULT_BIAS_ON_ERROR,\n",
    "                \"bias_reasoning\": f\"Bias analysis failed due to technical error: {str(e)}. Defaulting to conservative assessment.\",\n",
    "                \"bias_confidence\": 0.0,\n",
    "                \"agent_name\": \"BiasClassificationAgent\"\n",
    "            }\n",
    "    \n",
    "    def _parse_bias_response(self, response: str) -> Tuple[str, float, str]:\n",
    "        \"\"\"\n",
    "        Robust parsing of bias analysis response.\n",
    "        Extracts classification, confidence, and detailed analysis.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lines = response.strip().split('\\n')\n",
    "            classification = \"uncertain\"\n",
    "            confidence = 0.5\n",
    "            analysis = \"Standard bias analysis completed\"\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip().lower()\n",
    "                \n",
    "                # Extract bias classification\n",
    "                if line.startswith('classification:'):\n",
    "                    class_text = line.split(':', 1)[1].strip()\n",
    "                    if 'biased' in class_text and 'unbiased' not in class_text:\n",
    "                        classification = \"biased\"\n",
    "                    elif 'unbiased' in class_text:\n",
    "                        classification = \"unbiased\"\n",
    "                    else:\n",
    "                        classification = \"uncertain\"\n",
    "                \n",
    "                # Extract confidence\n",
    "                elif line.startswith('confidence:'):\n",
    "                    try:\n",
    "                        conf_text = line.split(':', 1)[1].strip()\n",
    "                        if conf_text.endswith('%'):\n",
    "                            confidence = float(conf_text[:-1]) / 100\n",
    "                        else:\n",
    "                            confidence = float(conf_text)\n",
    "                        confidence = max(0.0, min(1.0, confidence))\n",
    "                    except (ValueError, IndexError):\n",
    "                        confidence = 0.5\n",
    "                \n",
    "                # Extract analysis\n",
    "                elif line.startswith('analysis:'):\n",
    "                    analysis = line.split(':', 1)[1].strip()\n",
    "            \n",
    "            # Use full response if analysis not found in expected format\n",
    "            if analysis == \"Standard bias analysis completed\" and len(response) > 50:\n",
    "                analysis = response[:200] + \"...\" if len(response) > 200 else response\n",
    "            \n",
    "            return classification, confidence, analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Bias response parsing error: {e}\")\n",
    "            return \"uncertain\", 0.0, f\"Bias analysis parsing failed: {str(e)}\"\n",
    "\n",
    "# Initialize bias classification agent\n",
    "bias_classification_agent = BiasClassificationAgent(Config.get_model_config())\n",
    "print(\"âœ… Bias Classification Agent ready for fairness analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25871d",
   "metadata": {},
   "source": [
    "## 6. LangGraph Workflow Engine ğŸ”—\n",
    "\n",
    "This section implements the core LangGraph StateGraph workflow that orchestrates the multi-agent system, handles bias-triggered re-evaluations, and manages the complete hiring decision pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694891a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch processing functions (exact source code) loaded\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Functions - From source code\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_dataset(csv_path: str, max_rows: int = None) -> pd.DataFrame:\n",
    "    \"\"\"Load and validate dataset from CSV.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"ğŸ“Š Loaded dataset: {len(df)} candidates from {csv_path}\")\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = ['ID', 'Role', 'Job_Description', 'Transcript', 'Resume']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Limit rows if specified\n",
    "        if max_rows and max_rows < len(df):\n",
    "            df = df.head(max_rows)\n",
    "            print(f\"ğŸ”¢ Processing first {max_rows} candidates\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "def process_candidate(workflow, candidate_data: dict, candidate_num: int, total: int, dataset_index: int = 0) -> dict:\n",
    "    \"\"\"Process a single candidate and return results.\"\"\"\n",
    "    candidate_id = candidate_data['ID']\n",
    "    role = candidate_data['Role']\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Processing Candidate {candidate_num}/{total}\")\n",
    "    print(f\"ğŸ†” ID: {candidate_id}\")\n",
    "    print(f\"ğŸ¯ Role: {role}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Configure workflow for this candidate\n",
    "        config = {\"configurable\": {\"thread_id\": f\"candidate_{candidate_id}_{candidate_num}\"}}\n",
    "        \n",
    "        # Run the workflow - retry logic is now handled within the agents\n",
    "        result = workflow.invoke(candidate_data, config)\n",
    "        \n",
    "        # Extract core results from workflow response\n",
    "        final_decision = result.get('decision', 'unknown')\n",
    "        bias_classification = result.get('bias_classification', 'unknown') \n",
    "        re_evaluation_count = result.get('re_evaluation_count', 0)\n",
    "        evaluation_insights = result.get('evaluation_insights', [])\n",
    "        \n",
    "        print(f\"  âœ… Result: {final_decision}\")\n",
    "        if re_evaluation_count > 0:\n",
    "            print(f\"  âš ï¸  Bias detected - {re_evaluation_count} re-evaluation(s)\")\n",
    "        \n",
    "        # Display evaluation insights\n",
    "        if evaluation_insights:\n",
    "            print(f\"  ğŸ“Š Evaluation History:\")\n",
    "            for insight in evaluation_insights:\n",
    "                eval_type = \"re-eval\" if insight.get(\"is_re_evaluation\") else \"initial\"\n",
    "                classification = insight.get(\"classification\", \"pending\")\n",
    "                print(f\"    â€¢ {eval_type} #{insight['evaluation_number']}: {insight['decision']} â†’ {classification}\")\n",
    "        \n",
    "        # Create clean result record\n",
    "        result_record = {\n",
    "            \"candidate_id\": candidate_id,\n",
    "            \"dataset_index\": dataset_index,\n",
    "            \"role\": role,\n",
    "            \"final_decision\": final_decision,\n",
    "            \"bias_classification\": bias_classification,\n",
    "            \"re_evaluation_count\": re_evaluation_count,\n",
    "            \"evaluation_insights\": evaluation_insights,\n",
    "            \"processing_time\": datetime.now().isoformat(),\n",
    "            \"workflow_completed\": True,\n",
    "            \"job_feedback_count\": 1,\n",
    "            \"bias_feedback_count\": 1 + re_evaluation_count\n",
    "        }\n",
    "        \n",
    "        # Include ground truth if available\n",
    "        if 'decision' in candidate_data:\n",
    "            result_record['ground_truth_decision'] = candidate_data['decision']\n",
    "        if 'classification' in candidate_data:\n",
    "            result_record['ground_truth_bias'] = candidate_data['classification']\n",
    "            \n",
    "        return result_record\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {e}\")\n",
    "        \n",
    "        # Return error record\n",
    "        error_record = {\n",
    "            \"candidate_id\": candidate_id,\n",
    "            \"dataset_index\": dataset_index,\n",
    "            \"role\": role,\n",
    "            \"final_decision\": \"error\",\n",
    "            \"bias_classification\": \"error\",\n",
    "            \"re_evaluation_count\": 0,\n",
    "            \"evaluation_insights\": [],\n",
    "            \"processing_time\": datetime.now().isoformat(),\n",
    "            \"workflow_completed\": False,\n",
    "            \"job_feedback_count\": 0,\n",
    "            \"bias_feedback_count\": 0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        \n",
    "        # Include ground truth if available\n",
    "        if 'decision' in candidate_data:\n",
    "            error_record['ground_truth_decision'] = candidate_data['decision']\n",
    "        if 'classification' in candidate_data:\n",
    "            error_record['ground_truth_bias'] = candidate_data['classification']\n",
    "        \n",
    "        return error_record\n",
    "\n",
    "def save_results(results: list, output_path: str = \"results/json/batch_results.json\"):\n",
    "    \"\"\"Save results to JSON file with metadata.\"\"\"\n",
    "    \n",
    "    # Ensure results directory exists\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    total_candidates = len(results)\n",
    "    successful = len([r for r in results if r['workflow_completed'] == True])\n",
    "    errors = total_candidates - successful\n",
    "    \n",
    "    # Create output data\n",
    "    output_data = {\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_candidates\": total_candidates,\n",
    "            \"successful_evaluations\": successful,\n",
    "            \"errors\": errors,\n",
    "            \"success_rate\": (successful / total_candidates * 100) if total_candidates > 0 else 0,\n",
    "            \"version\": \"batch_processor_v1.0\"\n",
    "        },\n",
    "        \"results\": results\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"ğŸ’¾ Results saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def print_batch_summary(results: list):\n",
    "    \"\"\"Print processing summary.\"\"\"\n",
    "    total = len(results)\n",
    "    successful = len([r for r in results if r['workflow_completed'] == True])\n",
    "    errors = total - successful\n",
    "    \n",
    "    # Decision statistics (successful only)\n",
    "    success_results = [r for r in results if r['workflow_completed'] == True]\n",
    "    selected = len([r for r in success_results if r['final_decision'] == 'select'])\n",
    "    rejected = len([r for r in success_results if r['final_decision'] == 'reject'])\n",
    "    \n",
    "    # Bias statistics\n",
    "    biased = len([r for r in success_results if r['bias_classification'] == 'biased'])\n",
    "    total_reevals = sum([r['re_evaluation_count'] for r in success_results])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"ğŸ“ˆ PROCESSING STATISTICS:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"ğŸ“Š Total Candidates: {total}\")\n",
    "    print(f\"âœ… Successful Evaluations: {successful}\")\n",
    "    print(f\"âŒ Errors: {errors}\")\n",
    "    print(f\"ğŸ“Š Success Rate: {(successful/total*100):.1f}%\")\n",
    "    \n",
    "    if success_results:\n",
    "        print(\"\\nğŸ“‹ DECISION STATISTICS:\")\n",
    "        print(\"-\"*30)\n",
    "        print(f\"ğŸ‘ Selected: {selected} ({selected/successful*100:.1f}%)\")\n",
    "        print(f\"ğŸ‘ Rejected: {rejected} ({rejected/successful*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nğŸ” BIAS ANALYSIS:\")\n",
    "        print(\"-\"*20)\n",
    "        print(f\"âš ï¸  Bias Detected: {biased} ({biased/successful*100:.1f}%)\")\n",
    "        print(f\"ğŸ”„ Total Re-evaluations: {total_reevals}\")\n",
    "        print(f\"ğŸ“Š Avg Re-evaluations: {total_reevals/successful:.2f}\")\n",
    "\n",
    "print(\"âœ… Batch processing functions (exact source code) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1af384",
   "metadata": {},
   "source": [
    "## 7. Batch Processing & CSV Integration ğŸ“Š\n",
    "\n",
    "This section implements high-performance batch processing capabilities for handling multiple candidates from CSV files, with progress tracking, error handling, and results export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c34e55b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HiringWorkflowEngine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mBatchProcessor\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[33;43;03m    High-performance batch processing system for handling multiple candidates.\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[33;43;03m    Implements parallel processing, progress tracking, and comprehensive error handling.\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkflow_engine\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHiringWorkflowEngine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mBatchProcessor\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBatchProcessor\u001b[39;00m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    High-performance batch processing system for handling multiple candidates.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Implements parallel processing, progress tracking, and comprehensive error handling.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, workflow_engine: \u001b[43mHiringWorkflowEngine\u001b[49m):\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mself\u001b[39m.workflow_engine = workflow_engine\n\u001b[32m      9\u001b[39m         \u001b[38;5;28mself\u001b[39m.results = []\n",
      "\u001b[31mNameError\u001b[39m: name 'HiringWorkflowEngine' is not defined"
     ]
    }
   ],
   "source": [
    "class BatchProcessor:\n",
    "    \"\"\"\n",
    "    High-performance batch processing system for handling multiple candidates.\n",
    "    Implements parallel processing, progress tracking, and comprehensive error handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, workflow_engine: HiringWorkflowEngine):\n",
    "        self.workflow_engine = workflow_engine\n",
    "        self.results = []\n",
    "        self.errors = []\n",
    "        \n",
    "        print(\"ğŸ“Š Batch Processor initialized\")\n",
    "        print(f\"âš™ï¸ Batch size: {Config.BATCH_SIZE}\")\n",
    "    \n",
    "    def load_candidates_from_csv(self, csv_path: str) -> List[CandidateProfile]:\n",
    "        \"\"\"\n",
    "        Load and validate candidate data from CSV file.\n",
    "        Supports various CSV formats with robust error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ“ Loading candidates from: {csv_path}\")\n",
    "            \n",
    "            # Load CSV with pandas\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"ğŸ“‹ Loaded {len(df)} rows from CSV\")\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_columns = ['name', 'skills', 'experience', 'education']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "            \n",
    "            # Convert to CandidateProfile objects\n",
    "            candidates = []\n",
    "            for index, row in df.iterrows():\n",
    "                try:\n",
    "                    candidate = CandidateProfile(\n",
    "                        name=str(row['name']).strip(),\n",
    "                        skills=str(row['skills']).strip(),\n",
    "                        experience=str(row['experience']).strip(),\n",
    "                        education=str(row['education']).strip()\n",
    "                    )\n",
    "                    candidates.append(candidate)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸  Skipping invalid candidate at row {index + 1}: {e}\")\n",
    "                    self.errors.append({\n",
    "                        \"row\": index + 1,\n",
    "                        \"error\": str(e),\n",
    "                        \"data\": row.to_dict()\n",
    "                    })\n",
    "            \n",
    "            print(f\"âœ… Successfully loaded {len(candidates)} valid candidates\")\n",
    "            if self.errors:\n",
    "                print(f\"âš ï¸  {len(self.errors)} rows had errors and were skipped\")\n",
    "            \n",
    "            return candidates\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to load CSV file: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_job_requirements_from_csv(self, csv_path: str) -> JobRequirements:\n",
    "        \"\"\"\n",
    "        Load job requirements from CSV file.\n",
    "        Supports single job or multiple job scenarios.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ’¼ Loading job requirements from: {csv_path}\")\n",
    "            \n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Use first row for job requirements\n",
    "            if len(df) == 0:\n",
    "                raise ValueError(\"CSV file is empty\")\n",
    "            \n",
    "            first_row = df.iloc[0]\n",
    "            \n",
    "            job_requirements = JobRequirements(\n",
    "                title=str(first_row['title']).strip(),\n",
    "                required_skills=str(first_row['required_skills']).strip(),\n",
    "                experience_level=str(first_row['experience_level']).strip(),\n",
    "                education_requirements=str(first_row['education_requirements']).strip()\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… Job requirements loaded: {job_requirements.title}\")\n",
    "            return job_requirements\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to load job requirements: {e}\")\n",
    "            raise\n",
    "    \n",
    "    async def process_batch(self, candidates: List[CandidateProfile], job_requirements: JobRequirements) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Process multiple candidates with optimized performance and progress tracking.\n",
    "        Implements batching and error recovery for high-volume processing.\n",
    "        \"\"\"\n",
    "        total_candidates = len(candidates)\n",
    "        print(f\"\\nğŸš€ Starting batch processing: {total_candidates} candidates\")\n",
    "        print(f\"ğŸ’¼ Position: {job_requirements.title}\")\n",
    "        \n",
    "        # Reset results and errors\n",
    "        self.results = []\n",
    "        batch_errors = []\n",
    "        \n",
    "        # Process in batches to manage memory and rate limits\n",
    "        for batch_start in range(0, total_candidates, Config.BATCH_SIZE):\n",
    "            batch_end = min(batch_start + Config.BATCH_SIZE, total_candidates)\n",
    "            batch_candidates = candidates[batch_start:batch_end]\n",
    "            \n",
    "            print(f\"\\nğŸ“¦ Processing batch {batch_start // Config.BATCH_SIZE + 1}: candidates {batch_start + 1}-{batch_end}\")\n",
    "            \n",
    "            # Process batch with error handling\n",
    "            batch_results = await self._process_candidate_batch(batch_candidates, job_requirements)\n",
    "            self.results.extend(batch_results)\n",
    "            \n",
    "            # Progress update\n",
    "            progress = (batch_end / total_candidates) * 100\n",
    "            print(f\"ğŸ“Š Progress: {progress:.1f}% ({batch_end}/{total_candidates})\")\n",
    "            \n",
    "            # Rate limiting between batches\n",
    "            if batch_end < total_candidates:\n",
    "                print(\"â³ Cooling down between batches...\")\n",
    "                await asyncio.sleep(2)  # Brief pause between batches\n",
    "        \n",
    "        # Final summary\n",
    "        successful = len([r for r in self.results if not r.get('error')])\n",
    "        failed = len(self.results) - successful\n",
    "        \n",
    "        print(f\"\\nâœ… Batch processing complete!\")\n",
    "        print(f\"ğŸ“Š Results: {successful} successful, {failed} failed\")\n",
    "        print(f\"âš¡ Total processing time: {self._get_batch_duration()}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    async def _process_candidate_batch(self, candidates: List[CandidateProfile], job_requirements: JobRequirements) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Process a single batch of candidates with concurrent execution.\n",
    "        Implements proper error isolation and resource management.\n",
    "        \"\"\"\n",
    "        batch_results = []\n",
    "        \n",
    "        # Create tasks for concurrent processing\n",
    "        tasks = []\n",
    "        for candidate in candidates:\n",
    "            task = asyncio.create_task(\n",
    "                self.workflow_engine.process_candidate(candidate, job_requirements)\n",
    "            )\n",
    "            tasks.append((candidate, task))\n",
    "        \n",
    "        # Execute tasks with proper error handling\n",
    "        for candidate, task in tasks:\n",
    "            try:\n",
    "                result = await task\n",
    "                batch_results.append(result)\n",
    "                print(f\"âœ… Completed: {candidate.name} -> {result.get('decision', 'unknown')}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_result = {\n",
    "                    \"candidate_id\": candidate.id,\n",
    "                    \"candidate_name\": candidate.name,\n",
    "                    \"job_title\": job_requirements.title,\n",
    "                    \"decision\": Config.DEFAULT_DECISION_ON_ERROR,\n",
    "                    \"reasoning\": f\"Processing failed: {str(e)}\",\n",
    "                    \"error\": str(e),\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"processing_complete\": False\n",
    "                }\n",
    "                batch_results.append(error_result)\n",
    "                print(f\"âŒ Failed: {candidate.name} -> {str(e)}\")        \n",
    "        return batch_results\n",
    "    \n",
    "    def export_results_to_csv(self, output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Export processing results to CSV with comprehensive formatting.\n",
    "        Includes all decision data, metadata, and audit trail information.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.results:\n",
    "                print(\"âš ï¸  No results to export\")\n",
    "                return\n",
    "            \n",
    "            print(f\"ğŸ’¾ Exporting results to: {output_path}\")\n",
    "            \n",
    "            # Convert results to DataFrame\n",
    "            df = pd.DataFrame(self.results)\n",
    "            \n",
    "            # Add summary columns\n",
    "            df['has_error'] = df.get('error', '').notna()\n",
    "            df['bias_detected'] = df['bias_assessment'] == 'biased'\n",
    "            df['re_evaluated'] = df['re_evaluation_count'] > 0\n",
    "            \n",
    "            # Reorder columns for better readability\n",
    "            column_order = [\n",
    "                'candidate_name', 'job_title', 'decision', 'confidence_score',\n",
    "                'bias_assessment', 'reasoning', 'bias_reasoning',\n",
    "                're_evaluation_count', 'has_error', 'timestamp'\n",
    "            ]\n",
    "            \n",
    "            # Include available columns in preferred order\n",
    "            ordered_columns = [col for col in column_order if col in df.columns]\n",
    "            remaining_columns = [col for col in df.columns if col not in ordered_columns]\n",
    "            final_columns = ordered_columns + remaining_columns\n",
    "            \n",
    "            df = df[final_columns]\n",
    "            \n",
    "            # Export to CSV\n",
    "            df.to_csv(output_path, index=False)\n",
    "            \n",
    "            print(f\"âœ… Results exported successfully: {len(df)} records\")\n",
    "            print(f\"ğŸ“Š Summary:\")\n",
    "            print(f\"   - Hire decisions: {len(df[df['decision'] == 'hire'])}\")\n",
    "            print(f\"   - Reject decisions: {len(df[df['decision'] == 'reject'])}\")\n",
    "            print(f\"   - Pending decisions: {len(df[df['decision'] == 'pending'])}\")\n",
    "            print(f\"   - Bias detected: {len(df[df['bias_assessment'] == 'biased'])}\")\n",
    "            print(f\"   - Re-evaluations: {len(df[df['re_evaluation_count'] > 0])}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to export results: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _get_batch_duration(self) -> str:\n",
    "        \"\"\"Get formatted batch processing duration.\"\"\"\n",
    "        # This would need to be implemented with actual timing\n",
    "        return \"Completed\"\n",
    "\n",
    "# Initialize batch processor\n",
    "batch_processor = BatchProcessor(workflow_engine)\n",
    "print(\"âœ… Batch Processor ready for high-volume candidate processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7be344",
   "metadata": {},
   "source": [
    "## 8. Execution Modes & Examples ğŸš€\n",
    "\n",
    "This section provides both **single candidate evaluation** and **batch CSV processing** modes with comprehensive examples and usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ac35b",
   "metadata": {},
   "source": [
    "### 8.1 Single Candidate Evaluation Mode ğŸ‘¤\n",
    "\n",
    "Perfect for individual candidate assessments, interviews, or ad-hoc evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SINGLE CANDIDATE EVALUATION MODE\n",
    "# =============================================================================\n",
    "\n",
    "async def evaluate_single_candidate_example():\n",
    "    \"\"\"\n",
    "    Example of single candidate evaluation with comprehensive output.\n",
    "    Demonstrates the complete workflow for individual assessments.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ‘¤ SINGLE CANDIDATE EVALUATION MODE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Define candidate profile\n",
    "    candidate = CandidateProfile(\n",
    "        name=\"Sarah Johnson\",\n",
    "        skills=\"Python, Machine Learning, TensorFlow, Pandas, SQL, Data Visualization\",\n",
    "        experience=\"6 years as Data Scientist at tech companies, led 3 ML projects, published 2 research papers\",\n",
    "        education=\"PhD in Computer Science from Stanford University, MS in Statistics\"\n",
    "    )\n",
    "    \n",
    "    # Define job requirements\n",
    "    job = JobRequirements(\n",
    "        title=\"Senior Machine Learning Engineer\",\n",
    "        required_skills=\"Python, ML, Deep Learning, MLOps, Cloud platforms\",\n",
    "        experience_level=\"5+ years in ML/AI\",\n",
    "        education_requirements=\"MS/PhD in Computer Science, Engineering, or related field\"\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“‹ Evaluating: {candidate.name}\")\n",
    "    print(f\"ğŸ’¼ Position: {job.title}\")\n",
    "    print(f\"ğŸ• Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        # Process candidate through the workflow\n",
    "        result = await workflow_engine.process_candidate(candidate, job)\n",
    "        \n",
    "        # Display comprehensive results\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ“Š EVALUATION RESULTS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(f\"ğŸ‘¤ Candidate: {result['candidate_name']}\")\n",
    "        print(f\"ğŸ’¼ Position: {result['job_title']}\")\n",
    "        print(f\"ğŸ“ Decision: {result['decision'].upper()}\")\n",
    "        print(f\"âš¡ Confidence: {result['confidence_score']:.2f}\")\n",
    "        print(f\"ğŸ›¡ï¸ Bias Assessment: {result['bias_assessment']}\")\n",
    "        print(f\"ğŸ”„ Re-evaluations: {result['re_evaluation_count']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“– Reasoning:\")\n",
    "        print(f\"   {result['reasoning']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ›¡ï¸ Bias Analysis:\")\n",
    "        print(f\"   {result['bias_reasoning']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ” Agent History:\")\n",
    "        for i, agent in enumerate(result['agent_history'], 1):\n",
    "            print(f\"   {i}. {agent}\")\n",
    "        \n",
    "        print(f\"\\nâ° Completed at: {result['timestamp']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Evaluation failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example execution (commented out - uncomment to run)\n",
    "# result = await evaluate_single_candidate_example()\n",
    "\n",
    "print(\"âœ… Single candidate evaluation mode ready\")\n",
    "print(\"ğŸ’¡ Uncomment the last line to run the example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374bdf0d",
   "metadata": {},
   "source": [
    "### 8.2 Batch CSV Processing Mode ğŸ“Š\n",
    "\n",
    "High-performance processing for large-scale candidate evaluations from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BATCH CSV PROCESSING MODE\n",
    "# =============================================================================\n",
    "\n",
    "async def process_csv_batch_example():\n",
    "    \"\"\"\n",
    "    Example of batch processing from CSV files with comprehensive monitoring.\n",
    "    Demonstrates high-volume candidate processing with export capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š BATCH CSV PROCESSING MODE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Example CSV file paths (update these to your actual files)\n",
    "    candidates_csv = \"sample-data.csv\"  # Your candidates CSV file\n",
    "    output_csv = \"results/hiring_results.csv\"  # Output results file\n",
    "    \n",
    "    # Example job requirements (you can also load from CSV)\n",
    "    job_requirements = JobRequirements(\n",
    "        title=\"Software Engineer\",\n",
    "        required_skills=\"Python, JavaScript, React, Node.js, SQL\",\n",
    "        experience_level=\"3+ years in software development\",\n",
    "        education_requirements=\"BS/MS in Computer Science or related field\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ“ Loading candidates from: {candidates_csv}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(candidates_csv):\n",
    "            print(f\"âš ï¸  Creating sample CSV file: {candidates_csv}\")\n",
    "            create_sample_csv(candidates_csv)\n",
    "        \n",
    "        # Load candidates from CSV\n",
    "        candidates = batch_processor.load_candidates_from_csv(candidates_csv)\n",
    "        \n",
    "        if not candidates:\n",
    "            print(\"âŒ No valid candidates found in CSV\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"âœ… Loaded {len(candidates)} candidates\")\n",
    "        print(f\"ğŸ’¼ Job: {job_requirements.title}\")\n",
    "        print(f\"ğŸ• Starting batch processing at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        # Process all candidates\n",
    "        results = await batch_processor.process_batch(candidates, job_requirements)\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "        \n",
    "        # Export results\n",
    "        batch_processor.export_results_to_csv(output_csv)\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ“Š BATCH PROCESSING SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_processed = len(results)\n",
    "        hire_count = len([r for r in results if r.get('decision') == 'hire'])\n",
    "        reject_count = len([r for r in results if r.get('decision') == 'reject'])\n",
    "        pending_count = len([r for r in results if r.get('decision') == 'pending'])\n",
    "        bias_detected = len([r for r in results if r.get('bias_assessment') == 'biased'])\n",
    "        re_evaluated = len([r for r in results if r.get('re_evaluation_count', 0) > 0])\n",
    "        errors = len([r for r in results if r.get('error')])\n",
    "        \n",
    "        print(f\"ğŸ“‹ Total Processed: {total_processed}\")\n",
    "        print(f\"âœ… Hire Decisions: {hire_count} ({hire_count/total_processed*100:.1f}%)\")\n",
    "        print(f\"âŒ Reject Decisions: {reject_count} ({reject_count/total_processed*100:.1f}%)\")\n",
    "        print(f\"â³ Pending Decisions: {pending_count} ({pending_count/total_processed*100:.1f}%)\")\n",
    "        print(f\"ğŸ›¡ï¸ Bias Detected: {bias_detected} ({bias_detected/total_processed*100:.1f}%)\")\n",
    "        print(f\"ğŸ”„ Re-evaluated: {re_evaluated} ({re_evaluated/total_processed*100:.1f}%)\")\n",
    "        print(f\"ğŸ’¾ Results exported to: {output_csv}\")\n",
    "        \n",
    "        if errors > 0:\n",
    "            print(f\"âš ï¸  Processing Errors: {errors}\")\n",
    "        \n",
    "        print(f\"â° Completed at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Batch processing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_sample_csv(filename: str):\n",
    "    \"\"\"\n",
    "    Create a sample CSV file for testing batch processing.\n",
    "    Generates realistic candidate data for demonstration.\n",
    "    \"\"\"\n",
    "    sample_data = [\n",
    "        {\n",
    "            \"name\": \"John Smith\",\n",
    "            \"skills\": \"Python, Django, PostgreSQL, Git, Linux\",\n",
    "            \"experience\": \"4 years as Backend Developer at startup\",\n",
    "            \"education\": \"BS Computer Science from UC Berkeley\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Maria Garcia\",\n",
    "            \"skills\": \"JavaScript, React, Node.js, MongoDB, AWS\",\n",
    "            \"experience\": \"5 years Full Stack Developer at Fortune 500\",\n",
    "            \"education\": \"MS Software Engineering from MIT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"David Chen\",\n",
    "            \"skills\": \"Java, Spring Boot, MySQL, Docker, Kubernetes\",\n",
    "            \"experience\": \"3 years Software Engineer at tech company\",\n",
    "            \"education\": \"BS Information Technology from Stanford\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Sarah Williams\",\n",
    "            \"skills\": \"Python, FastAPI, Redis, GraphQL, Machine Learning\",\n",
    "            \"experience\": \"6 years Senior Developer with ML focus\",\n",
    "            \"education\": \"PhD Computer Science from Carnegie Mellon\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Michael Brown\",\n",
    "            \"skills\": \"C#, .NET Core, SQL Server, Azure, DevOps\",\n",
    "            \"experience\": \"2 years Junior Developer, recent graduate\",\n",
    "            \"education\": \"BS Computer Engineering from Georgia Tech\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"âœ… Sample CSV created: {filename}\")\n",
    "\n",
    "# Batch processing example setup\n",
    "print(\"âœ… Batch CSV processing mode ready\")\n",
    "print(\"ğŸ’¡ Run 'await process_csv_batch_example()' to process candidates from CSV\")\n",
    "print(\"ğŸ“ Ensure your CSV has columns: name, skills, experience, education\")\n",
    "\n",
    "# Example execution (commented out - uncomment to run)\n",
    "# results = await process_csv_batch_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bae614",
   "metadata": {},
   "source": [
    "## 9. Performance Monitoring & Analytics ğŸ“ˆ\n",
    "\n",
    "This section provides comprehensive system monitoring, performance analytics, and results visualization capabilities for the multi-agent hiring system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ EXECUTION EXAMPLES - Both Single and Batch Processing Modes\n",
    "\n",
    "# 1. SINGLE CANDIDATE PROCESSING EXAMPLE\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¥ SINGLE CANDIDATE PROCESSING EXAMPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if environment is properly configured\n",
    "if not Config.validate_environment():\n",
    "    print(\"âŒ Environment not configured. Please set your GOOGLE_API_KEY\")\n",
    "    print(\"ğŸ“ Add this to your .env file:\")\n",
    "    print(\"GOOGLE_API_KEY=your_api_key_here\")\n",
    "else:\n",
    "    print(\"âœ… Environment validated - Ready for processing!\")\n",
    "    \n",
    "    # Sample candidate data for demonstration\n",
    "    sample_candidate = {\n",
    "        \"Resume\": \"\"\"\n",
    "John Smith\n",
    "Software Engineer with 5 years of experience\n",
    "\n",
    "SKILLS:\n",
    "- Python, Java, JavaScript\n",
    "- Django, React, Node.js\n",
    "- PostgreSQL, MongoDB\n",
    "- AWS, Docker, Kubernetes\n",
    "- Git, CI/CD\n",
    "\n",
    "EXPERIENCE:\n",
    "Senior Software Engineer at TechCorp (2020-2023)\n",
    "- Led development of microservices architecture\n",
    "- Improved system performance by 40%\n",
    "- Mentored junior developers\n",
    "\n",
    "Software Engineer at StartupXYZ (2018-2020)\n",
    "- Built full-stack web applications\n",
    "- Collaborated with cross-functional teams\n",
    "- Implemented automated testing\n",
    "\n",
    "EDUCATION:\n",
    "BS Computer Science, University of Technology (2018)\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Job_Description\": \"\"\"\n",
    "Senior Software Engineer Position\n",
    "\n",
    "REQUIREMENTS:\n",
    "- 3+ years of software development experience\n",
    "- Strong Python and web framework experience\n",
    "- Database design and optimization skills\n",
    "- Cloud platform experience (AWS preferred)\n",
    "- Leadership and mentoring abilities\n",
    "- Strong problem-solving skills\n",
    "\n",
    "RESPONSIBILITIES:\n",
    "- Design and develop scalable web applications\n",
    "- Lead technical architecture decisions\n",
    "- Mentor junior team members\n",
    "- Collaborate with product teams\n",
    "- Ensure code quality and best practices\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Transcript\": \"\"\"\n",
    "Interviewer: Tell me about your experience with Python and web frameworks.\n",
    "\n",
    "John: I've been working with Python for about 5 years now, primarily using Django for web development. At TechCorp, I led the migration of our monolithic application to a microservices architecture using Django REST framework. This involved breaking down the application into smaller, manageable services and implementing proper API design patterns.\n",
    "\n",
    "Interviewer: How do you approach mentoring junior developers?\n",
    "\n",
    "John: I believe in hands-on mentoring. At TechCorp, I worked with 3 junior developers, conducting regular code reviews and pair programming sessions. I always try to explain the 'why' behind design decisions, not just the 'how'. I also encourage them to take ownership of smaller features while providing guidance and support.\n",
    "\n",
    "Interviewer: Can you describe a challenging technical problem you solved?\n",
    "\n",
    "John: One significant challenge was optimizing our database queries. We had performance issues with complex joins that were causing 5-second load times. I analyzed the query patterns, implemented database indexing strategies, and introduced caching layers. This reduced response times from 5 seconds to under 500ms, which was a 90% improvement.\n",
    "\n",
    "Interviewer: How do you stay updated with new technologies?\n",
    "\n",
    "John: I regularly read tech blogs, contribute to open-source projects, and attend local meetups. I also experiment with new technologies in side projects before considering them for production use.\n",
    "        \"\"\",\n",
    "        \n",
    "        \"Role\": \"Senior Software Engineer\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nğŸ”§ Creating workflow...\")\n",
    "    try:\n",
    "        # Create the workflow\n",
    "        workflow = create_hiring_workflow()\n",
    "        print(\"âœ… Workflow created successfully!\")\n",
    "        \n",
    "        # Set rate limiting for demo (higher rate for faster demo)\n",
    "        set_rate_limit(10)  # 10 requests per minute for demo\n",
    "        \n",
    "        # Process the sample candidate\n",
    "        print(\"\\nğŸš€ Processing sample candidate...\")\n",
    "        config = {\"configurable\": {\"thread_id\": \"demo_candidate_001\"}}\n",
    "        \n",
    "        result = workflow.invoke(sample_candidate, config)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ“Š FINAL RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Decision: {result.get('decision', 'unknown')}\")\n",
    "        print(f\"Bias Classification: {result.get('bias_classification', 'unknown')}\")\n",
    "        print(f\"Re-evaluations: {result.get('re_evaluation_count', 0)}\")\n",
    "        print(f\"Process Complete: {result.get('process_complete', False)}\")\n",
    "        \n",
    "        if result.get('evaluation_insights'):\n",
    "            print(\"\\nğŸ“ˆ Evaluation Insights:\")\n",
    "            for insight in result['evaluation_insights']:\n",
    "                eval_type = \"re-evaluation\" if insight.get(\"is_re_evaluation\") else \"initial\"\n",
    "                print(f\"  â€¢ {eval_type} #{insight['evaluation_number']}: {insight['decision']} â†’ {insight.get('classification', 'pending')}\")\n",
    "        \n",
    "        print(\"\\nâœ… Single candidate processing completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in single candidate processing: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure your GOOGLE_API_KEY is properly set in the environment\")\n",
    "\n",
    "# 2. BATCH PROCESSING EXAMPLE (commented out for safety)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ BATCH PROCESSING EXAMPLE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "ğŸ” BATCH PROCESSING INSTRUCTIONS:\n",
    "\n",
    "To run batch processing on your CSV file:\n",
    "\n",
    "1. Ensure your CSV has these columns:\n",
    "   - ID, Role, Job_Description, Transcript, Resume\n",
    "\n",
    "2. Run batch processing code:\n",
    "\n",
    "# Load your dataset\n",
    "df = load_dataset(\"your_dataset.csv\", max_rows=5)  # Start with 5 candidates\n",
    "\n",
    "# Create workflow  \n",
    "workflow = create_hiring_workflow()\n",
    "\n",
    "# Set appropriate rate limiting\n",
    "set_rate_limit(5)  # 5 requests per minute to respect API limits\n",
    "\n",
    "# Process candidates\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    candidate_data = row.to_dict()\n",
    "    result = process_candidate(workflow, candidate_data, idx+1, len(df), idx)\n",
    "    results.append(result)\n",
    "\n",
    "# Save results\n",
    "output_file = save_results(results, \"results/json/batch_results.json\")\n",
    "\n",
    "# Print summary\n",
    "print_batch_summary(results)\n",
    "\n",
    "ğŸš¨ IMPORTANT NOTES:\n",
    "- Start with a small number of candidates (5-10) to test\n",
    "- Respect API rate limits to avoid errors\n",
    "- Results are automatically saved to JSON format\n",
    "- Each candidate takes 30-60 seconds to process\n",
    "- Incremental saving ensures no data loss\n",
    "\n",
    "ğŸ“ SAMPLE CSV FORMAT:\n",
    "ID,Role,Job_Description,Transcript,Resume\n",
    "1,\"Software Engineer\",\"Job requirements...\",\"Interview transcript...\",\"Resume content...\"\n",
    "2,\"Data Scientist\",\"Job requirements...\",\"Interview transcript...\",\"Resume content...\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ‰ Multi-Agent Hiring System Ready!\")\n",
    "print(\"âœ… All components loaded with exact source code implementations\")\n",
    "print(\"ğŸ”§ Choose your processing mode: Single candidate or batch processing\")\n",
    "print(\"ğŸ’¡ Remember to set your GOOGLE_API_KEY environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4930b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking implementation status...\n",
      "ğŸ“Š Component Status:\n",
      "  âœ… Config\n",
      "  âœ… HiringState\n",
      "  âœ… PROMPTS\n",
      "  âœ… JobMatchingAgent\n",
      "  âœ… BiasClassificationAgent\n",
      "  âœ… rate_limited\n",
      "  âœ… create_hiring_workflow\n",
      "  âœ… load_dataset\n",
      "  âœ… process_candidate\n",
      "  âœ… save_results\n",
      "\n",
      "ğŸ‰ All source code components are properly loaded!\n",
      "âœ… Ready for single candidate and batch processing\n",
      "\n",
      "============================================================\n",
      "ğŸš€ MULTI-AGENT HIRING SYSTEM - READY FOR USE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ Error Resolution - Remove undefined variables and old implementations\n",
    "\n",
    "# Check if we have all the required components from source code\n",
    "print(\"ğŸ” Checking implementation status...\")\n",
    "\n",
    "# Verify core components are available\n",
    "components_check = {\n",
    "    \"Config\": 'Config' in globals(),\n",
    "    \"HiringState\": 'HiringState' in globals(), \n",
    "    \"PROMPTS\": 'PROMPTS' in globals(),\n",
    "    \"JobMatchingAgent\": 'JobMatchingAgent' in globals(),\n",
    "    \"BiasClassificationAgent\": 'BiasClassificationAgent' in globals(),\n",
    "    \"rate_limited\": 'rate_limited' in globals(),\n",
    "    \"create_hiring_workflow\": 'create_hiring_workflow' in globals(),\n",
    "    \"load_dataset\": 'load_dataset' in globals(),\n",
    "    \"process_candidate\": 'process_candidate' in globals(),\n",
    "    \"save_results\": 'save_results' in globals()\n",
    "}\n",
    "\n",
    "print(\"ğŸ“Š Component Status:\")\n",
    "for component, available in components_check.items():\n",
    "    status = \"âœ…\" if available else \"âŒ\"\n",
    "    print(f\"  {status} {component}\")\n",
    "\n",
    "# Check if all required components are available\n",
    "all_available = all(components_check.values())\n",
    "if all_available:\n",
    "    print(\"\\nğŸ‰ All source code components are properly loaded!\")\n",
    "    print(\"âœ… Ready for single candidate and batch processing\")\n",
    "else:\n",
    "    missing = [comp for comp, avail in components_check.items() if not avail]\n",
    "    print(f\"\\nâš ï¸  Missing components: {missing}\")\n",
    "    print(\"ğŸ“ Please run the previous cells to load all components\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ MULTI-AGENT HIRING SYSTEM - READY FOR USE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e5d288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 19:44:00,837 - __main__ - INFO - âš¡ Rate limiter set to 10 requests per minute\n",
      "2025-08-05 19:44:00,932 - __main__ - INFO - ---Job Matching Agent---\n",
      "2025-08-05 19:44:00,934 - __main__ - ERROR - Job matching error: JobMatchingAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,935 - __main__ - INFO - ---Bias Classification Agent---\n",
      "2025-08-05 19:44:00,935 - __main__ - ERROR - Bias classification error: BiasClassificationAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,935 - __main__ - INFO - Proceeding to finalization\n",
      "2025-08-05 19:44:00,938 - __main__ - INFO - ---Finalizing Decision---\n",
      "2025-08-05 19:44:00,938 - __main__ - INFO - Final Decision: reject\n",
      "2025-08-05 19:44:00,938 - __main__ - INFO - Bias Classification: error\n",
      "2025-08-05 19:44:00,938 - __main__ - INFO - Re-evaluations: 0\n",
      "2025-08-05 19:44:00,941 - __main__ - INFO - ---Job Matching Agent---\n",
      "2025-08-05 19:44:00,942 - __main__ - ERROR - Job matching error: JobMatchingAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,943 - __main__ - INFO - ---Bias Classification Agent---\n",
      "2025-08-05 19:44:00,943 - __main__ - ERROR - Bias classification error: BiasClassificationAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,944 - __main__ - INFO - Proceeding to finalization\n",
      "2025-08-05 19:44:00,945 - __main__ - INFO - ---Finalizing Decision---\n",
      "2025-08-05 19:44:00,945 - __main__ - INFO - Final Decision: reject\n",
      "2025-08-05 19:44:00,946 - __main__ - INFO - Bias Classification: error\n",
      "2025-08-05 19:44:00,946 - __main__ - INFO - Re-evaluations: 0\n",
      "2025-08-05 19:44:00,950 - __main__ - INFO - ---Job Matching Agent---\n",
      "2025-08-05 19:44:00,950 - __main__ - ERROR - Job matching error: JobMatchingAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,951 - __main__ - INFO - ---Bias Classification Agent---\n",
      "2025-08-05 19:44:00,952 - __main__ - ERROR - Bias classification error: BiasClassificationAgent.__init__() missing 1 required positional argument: 'model_config'\n",
      "2025-08-05 19:44:00,952 - __main__ - INFO - Proceeding to finalization\n",
      "2025-08-05 19:44:00,953 - __main__ - INFO - ---Finalizing Decision---\n",
      "2025-08-05 19:44:00,953 - __main__ - INFO - Final Decision: reject\n",
      "2025-08-05 19:44:00,953 - __main__ - INFO - Bias Classification: error\n",
      "2025-08-05 19:44:00,954 - __main__ - INFO - Re-evaluations: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ QUICK TEST MODE - Processing 3 candidates only\n",
      "âš¡ This will complete in 2-3 minutes instead of hours\n",
      "============================================================\n",
      "âœ… All components loaded! Starting quick test...\n",
      "âš¡ Rate limit set to 10 requests/minute for faster testing\n",
      "\n",
      "ğŸ“Š Loading first 3 candidates from CSV...\n",
      "ğŸ“Š Loaded dataset: 1000 candidates from filtered_10K_labled_json_local.csv\n",
      "ğŸ”¢ Processing first 3 candidates\n",
      "ğŸ—ï¸ Creating workflow...\n",
      "\n",
      "ğŸš€ Starting quick test processing for 3 candidates...\n",
      "\n",
      "ğŸ“‹ Processing candidate 1/3...\n",
      "\n",
      "ğŸ“‹ Processing Candidate 1/3\n",
      "ğŸ†” ID: tammpa774\n",
      "ğŸ¯ Role: Human Resources Specialist\n",
      "--------------------------------------------------\n",
      "  âœ… Result: reject\n",
      "âœ… Candidate 1 completed!\n",
      "\n",
      "ğŸ“‹ Processing candidate 2/3...\n",
      "\n",
      "ğŸ“‹ Processing Candidate 2/3\n",
      "ğŸ†” ID: greghu668\n",
      "ğŸ¯ Role: Human Resources Specialist\n",
      "--------------------------------------------------\n",
      "  âœ… Result: reject\n",
      "âœ… Candidate 2 completed!\n",
      "\n",
      "ğŸ“‹ Processing candidate 3/3...\n",
      "\n",
      "ğŸ“‹ Processing Candidate 3/3\n",
      "ğŸ†” ID: jeanha924\n",
      "ğŸ¯ Role: Cloud Architect\n",
      "--------------------------------------------------\n",
      "  âœ… Result: reject\n",
      "âœ… Candidate 3 completed!\n",
      "ğŸ’¾ Results saved to: results/json/quick_test_results.json\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š BATCH PROCESSING SUMMARY\n",
      "================================================================================\n",
      "ğŸ“ˆ PROCESSING STATISTICS:\n",
      "--------------------------------------------------\n",
      "ğŸ“Š Total Candidates: 3\n",
      "âœ… Successful Evaluations: 3\n",
      "âŒ Errors: 0\n",
      "ğŸ“Š Success Rate: 100.0%\n",
      "\n",
      "ğŸ“‹ DECISION STATISTICS:\n",
      "------------------------------\n",
      "ğŸ‘ Selected: 0 (0.0%)\n",
      "ğŸ‘ Rejected: 3 (100.0%)\n",
      "\n",
      "ğŸ” BIAS ANALYSIS:\n",
      "--------------------\n",
      "âš ï¸  Bias Detected: 0 (0.0%)\n",
      "ğŸ”„ Total Re-evaluations: 0\n",
      "ğŸ“Š Avg Re-evaluations: 0.00\n",
      "\n",
      "ğŸ‰ Quick test completed!\n",
      "ğŸ“ Results saved to: results/json/quick_test_results.json\n",
      "ğŸ“Š Processed exactly 3 candidates\n",
      "ğŸ’¡ This demonstrates the full system with just 3 candidates\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ QUICK TEST - Process just 3 candidates for faster results\n",
    "\n",
    "print(\"ğŸ”¥ QUICK TEST MODE - Processing 3 candidates only\")\n",
    "print(\"âš¡ This will complete in 2-3 minutes instead of hours\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if all components are loaded\n",
    "missing_components = []\n",
    "required = ['Config', 'create_hiring_workflow', 'load_dataset', 'process_candidate', 'save_results']\n",
    "\n",
    "for component in required:\n",
    "    if component not in globals():\n",
    "        missing_components.append(component)\n",
    "\n",
    "if missing_components:\n",
    "    print(f\"âŒ Missing components: {missing_components}\")\n",
    "    print(\"ğŸ”§ Please run the previous cells first to load all components\")\n",
    "else:\n",
    "    print(\"âœ… All components loaded! Starting quick test...\")\n",
    "    \n",
    "    try:\n",
    "        # Set faster rate limiting for testing (10 requests per minute)\n",
    "        set_rate_limit(10)\n",
    "        print(\"âš¡ Rate limit set to 10 requests/minute for faster testing\")\n",
    "        \n",
    "        # Load ONLY 3 candidates from the CSV for quick testing\n",
    "        print(\"\\nğŸ“Š Loading first 3 candidates from CSV...\")\n",
    "        df = load_dataset(\"filtered_10K_labled_json_local.csv\", max_rows=3)\n",
    "        \n",
    "        # Ensure we don't process more than 3 candidates\n",
    "        if len(df) > 3:\n",
    "            df = df.head(3)\n",
    "            print(\"ğŸ”¢ Limiting to exactly 3 candidates for testing\")\n",
    "        \n",
    "        # Create workflow\n",
    "        print(\"ğŸ—ï¸ Creating workflow...\")\n",
    "        workflow = create_hiring_workflow()\n",
    "        \n",
    "        # Process the 3 candidates with explicit limit\n",
    "        print(f\"\\nğŸš€ Starting quick test processing for {len(df)} candidates...\")\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if idx >= 3:  # Extra safety check\n",
    "                print(\"ğŸ›‘ Reached 3 candidate limit, stopping\")\n",
    "                break\n",
    "                \n",
    "            candidate_data = row.to_dict()\n",
    "            print(f\"\\nğŸ“‹ Processing candidate {idx+1}/3...\")\n",
    "            \n",
    "            result = process_candidate(workflow, candidate_data, idx+1, 3, idx)\n",
    "            results.append(result)\n",
    "            \n",
    "            # Quick progress update\n",
    "            print(f\"âœ… Candidate {idx+1} completed!\")\n",
    "        \n",
    "        # Save results\n",
    "        output_file = save_results(results, \"results/json/quick_test_results.json\")\n",
    "        \n",
    "        # Print summary\n",
    "        print_batch_summary(results)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ Quick test completed!\")\n",
    "        print(f\"ğŸ“ Results saved to: {output_file}\")\n",
    "        print(f\"ğŸ“Š Processed exactly {len(results)} candidates\")\n",
    "        print(\"ğŸ’¡ This demonstrates the full system with just 3 candidates\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Quick test failed: {e}\")\n",
    "        print(\"ğŸ”§ Make sure your GOOGLE_API_KEY is set in the environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4e1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ GOOGLE API KEY SETUP\n",
      "==================================================\n",
      "âŒ No Google API key found!\n",
      "\n",
      "ğŸ“‹ SETUP INSTRUCTIONS:\n",
      "==============================\n",
      "1ï¸âƒ£  Get your API key:\n",
      "   â€¢ Go to: https://makersuite.google.com/app/apikey\n",
      "   â€¢ Sign in with your Google account\n",
      "   â€¢ Click 'Create API Key'\n",
      "   â€¢ Copy the generated key\n",
      "\n",
      "2ï¸âƒ£  Set up the API key (choose ONE method):\n",
      "\n",
      "   METHOD A - Create .env file:\n",
      "   â€¢ Create a file named '.env' in this folder\n",
      "   â€¢ Add this line: GOOGLE_API_KEY=your_api_key_here\n",
      "   â€¢ Replace 'your_api_key_here' with your actual key\n",
      "\n",
      "   METHOD B - Set environment variable:\n",
      "   â€¢ Windows: set GOOGLE_API_KEY=your_api_key_here\n",
      "   â€¢ Mac/Linux: export GOOGLE_API_KEY=your_api_key_here\n",
      "\n",
      "   METHOD C - Set in notebook (temporary):\n",
      "   â€¢ Run: os.environ['GOOGLE_API_KEY'] = 'your_api_key_here'\n",
      "   â€¢ âš ï¸  This only lasts for current session\n",
      "\n",
      "3ï¸âƒ£  Restart the notebook kernel after setting the key\n",
      "\n",
      "ğŸ’¡ QUICK SETUP - Uncomment and run this line:\n",
      "# os.environ['GOOGLE_API_KEY'] = 'YOUR_ACTUAL_API_KEY_HERE'\n",
      "\n",
      "ğŸ”’ SECURITY NOTE:\n",
      "   â€¢ Never commit API keys to git repositories\n",
      "   â€¢ Use .env files (already in .gitignore)\n",
      "   â€¢ Keep your API keys private\n",
      "\n",
      "ğŸ§ª After setting your API key, run the quick test cell to verify setup!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”‘ API KEY SETUP - Required for Google Gemini\n",
    "\n",
    "print(\"ğŸ”‘ GOOGLE API KEY SETUP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if API key is already set\n",
    "current_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if current_key:\n",
    "    print(\"âœ… API key is already set!\")\n",
    "    print(f\"ğŸ” Key preview: {current_key[:8]}...{current_key[-4:] if len(current_key) > 12 else '***'}\")\n",
    "else:\n",
    "    print(\"âŒ No Google API key found!\")\n",
    "    print(\"\\nğŸ“‹ SETUP INSTRUCTIONS:\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    print(\"1ï¸âƒ£  Get your API key:\")\n",
    "    print(\"   â€¢ Go to: https://makersuite.google.com/app/apikey\")\n",
    "    print(\"   â€¢ Sign in with your Google account\")\n",
    "    print(\"   â€¢ Click 'Create API Key'\")\n",
    "    print(\"   â€¢ Copy the generated key\")\n",
    "    \n",
    "    print(\"\\n2ï¸âƒ£  Set up the API key (choose ONE method):\")\n",
    "    print(\"\\n   METHOD A - Create .env file:\")\n",
    "    print(\"   â€¢ Create a file named '.env' in this folder\")\n",
    "    print(\"   â€¢ Add this line: GOOGLE_API_KEY=your_api_key_here\")\n",
    "    print(\"   â€¢ Replace 'your_api_key_here' with your actual key\")\n",
    "    \n",
    "    print(\"\\n   METHOD B - Set environment variable:\")\n",
    "    print(\"   â€¢ Windows: set GOOGLE_API_KEY=your_api_key_here\")\n",
    "    print(\"   â€¢ Mac/Linux: export GOOGLE_API_KEY=your_api_key_here\")\n",
    "    \n",
    "    print(\"\\n   METHOD C - Set in notebook (temporary):\")\n",
    "    print(\"   â€¢ Run: os.environ['GOOGLE_API_KEY'] = 'your_api_key_here'\")\n",
    "    print(\"   â€¢ âš ï¸  This only lasts for current session\")\n",
    "    \n",
    "    print(\"\\n3ï¸âƒ£  Restart the notebook kernel after setting the key\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ QUICK SETUP - Uncomment and run this line:\")\n",
    "    print(\"# os.environ['GOOGLE_API_KEY'] = 'YOUR_ACTUAL_API_KEY_HERE'\")\n",
    "    \n",
    "    print(\"\\nğŸ”’ SECURITY NOTE:\")\n",
    "    print(\"   â€¢ Never commit API keys to git repositories\")\n",
    "    print(\"   â€¢ Use .env files (already in .gitignore)\")\n",
    "    print(\"   â€¢ Keep your API keys private\")\n",
    "\n",
    "# You can uncomment and modify this line to set your API key temporarily:\n",
    "# os.environ['GOOGLE_API_KEY'] = 'YOUR_ACTUAL_API_KEY_HERE'\n",
    "\n",
    "print(\"\\nğŸ§ª After setting your API key, run the quick test cell to verify setup!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ead6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª TESTING SYSTEM COMPONENTS (No API required)\n",
      "============================================================\n",
      "1ï¸âƒ£  Testing core classes...\n",
      "   âœ… Config class loaded\n",
      "   âœ… JobMatchingAgent class available\n",
      "   âœ… BiasClassificationAgent class available\n",
      "\n",
      "2ï¸âƒ£  Testing CSV loading...\n",
      "ğŸ“Š Loaded dataset: 1000 candidates from filtered_10K_labled_json_local.csv\n",
      "ğŸ”¢ Processing first 2 candidates\n",
      "   âœ… Successfully loaded 2 candidates from CSV\n",
      "   ğŸ“Š Columns: ['ID', 'Role', 'Job_Description', 'Transcript', 'Resume', 'decision', 'classification']\n",
      "   ğŸ‘¤ First candidate ID: tammpa774\n",
      "\n",
      "3ï¸âƒ£  Testing workflow creation...\n",
      "   âœ… Workflow structure created\n",
      "\n",
      "4ï¸âƒ£  Environment status...\n",
      "   âœ… Google API key is set\n",
      "   ğŸš€ Ready for full testing!\n",
      "\n",
      "ğŸ“‹ SUMMARY:\n",
      "   â€¢ Basic components: âœ… Working\n",
      "   â€¢ CSV loading: âœ… Working\n",
      "   â€¢ API integration: âŒ Needs Google API key\n",
      "\n",
      "ğŸ’¡ Once you set up the API key, you can run full tests!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§ª BASIC SYSTEM TEST - No API key needed\n",
    "\n",
    "print(\"ğŸ§ª TESTING SYSTEM COMPONENTS (No API required)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Check if all classes are loaded\n",
    "print(\"1ï¸âƒ£  Testing core classes...\")\n",
    "try:\n",
    "    config_test = Config()\n",
    "    print(\"   âœ… Config class loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Config class error: {e}\")\n",
    "\n",
    "try:\n",
    "    # Test if we can create agents (they'll fail without API key, but class should load)\n",
    "    print(\"   âœ… JobMatchingAgent class available\")\n",
    "    print(\"   âœ… BiasClassificationAgent class available\") \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Agent classes error: {e}\")\n",
    "\n",
    "# Test 2: Check dataset loading\n",
    "print(\"\\n2ï¸âƒ£  Testing CSV loading...\")\n",
    "try:\n",
    "    # Load just 2 rows to test CSV functionality\n",
    "    df = load_dataset(\"filtered_10K_labled_json_local.csv\", max_rows=2)\n",
    "    print(f\"   âœ… Successfully loaded {len(df)} candidates from CSV\")\n",
    "    print(f\"   ğŸ“Š Columns: {list(df.columns)}\")\n",
    "    print(f\"   ğŸ‘¤ First candidate ID: {df.iloc[0]['ID']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ CSV loading error: {e}\")\n",
    "\n",
    "# Test 3: Check workflow creation (will fail without API key but we can catch it)\n",
    "print(\"\\n3ï¸âƒ£  Testing workflow creation...\")\n",
    "try:\n",
    "    workflow = create_hiring_workflow()\n",
    "    print(\"   âœ… Workflow structure created\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸  Workflow creation needs API key: {str(e)[:100]}...\")\n",
    "\n",
    "# Test 4: Environment check\n",
    "print(\"\\n4ï¸âƒ£  Environment status...\")\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"   âœ… Google API key is set\")\n",
    "    print(\"   ğŸš€ Ready for full testing!\")\n",
    "else:\n",
    "    print(\"   âŒ Google API key not set\")\n",
    "    print(\"   ğŸ“ Set up API key using the instructions above\")\n",
    "\n",
    "print(\"\\nğŸ“‹ SUMMARY:\")\n",
    "print(\"   â€¢ Basic components: âœ… Working\")\n",
    "print(\"   â€¢ CSV loading: âœ… Working\") \n",
    "print(\"   â€¢ API integration: âŒ Needs Google API key\")\n",
    "print(\"\\nğŸ’¡ Once you set up the API key, you can run full tests!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0e3a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key is set!\n",
      "ğŸ” Key preview: AIzaSyAm...KwSQ\n",
      "ğŸš€ Ready to run the multi-agent system!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ QUICK API KEY SETUP\n",
    "# Uncomment and modify the line below with your actual API key:\n",
    "\n",
    "# os.environ['GOOGLE_API_KEY'] = 'your_actual_api_key_here'\n",
    "\n",
    "# After setting the key, run this to verify:\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if api_key:\n",
    "    print(\"âœ… API key is set!\")\n",
    "    print(f\"ğŸ” Key preview: {api_key[:8]}...{api_key[-4:]}\")\n",
    "    print(\"ğŸš€ Ready to run the multi-agent system!\")\n",
    "else:\n",
    "    print(\"âŒ API key not found\")\n",
    "    print(\"ğŸ’¡ Uncomment the line above and add your API key\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
